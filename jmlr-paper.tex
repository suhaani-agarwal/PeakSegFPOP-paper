\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}
\usepackage{tikz}
%\usepackage{stfloats}
\usetikzlibrary{arrows}
\usepackage{natbib}
%\usepackage{hyperref}
%\newcommand{\url}[1]{#1}
%\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{fancyvrb}
\definecolor{good}{HTML}{6A3D9A}
\definecolor{bad}{HTML}{1F78B4}
\definecolor{noPeaks}{HTML}{F6F4BF}
\definecolor{peakStart}{HTML}{FFAFAF}
\definecolor{peakEnd}{HTML}{FF4C4C}
\definecolor{peaks}{HTML}{A445EE}
\VerbatimFootnotes

% provide arXiv number if available:
%\arxiv{arXiv:1703.03352}

% put your definitions there:
\usepackage{xcolor}
\definecolor{Ckt}{HTML}{E41A1C}
\definecolor{Min}{HTML}{4D4D4D}%grey30
%{B3B3B3}%grey70
\definecolor{MinMore}{HTML}{377EB8}
\definecolor{Data}{HTML}{984EA3}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\sign}{sign}
\DeclareMathOperator*{\Lik}{Lik}
\DeclareMathOperator*{\Peaks}{Peaks}
\DeclareMathOperator*{\HotSpots}{HotSpots}
\newcommand{\Cost}{\text{Cost}}
\DeclareMathOperator*{\Diag}{Diag}
\DeclareMathOperator*{\TPR}{TPR}
\DeclareMathOperator*{\Segments}{Segments}
\DeclareMathOperator*{\Changes}{Changes}
\DeclareMathOperator*{\FPR}{FPR}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\minimize}{minimize}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\NN}{\mathbb N}
\newcommand{\RR}{\mathbb R}

\begin{document}

\title{Constrained dynamic programming and supervised
penalty learning algorithms for 
peak detection in genomic data}

\author{%
  \name Toby Dylan Hocking \email toby.hocking@nau.edu \\
  \addr School of Informatics, Computing, and Cyber Systems\\
  Northern Arizona University\\
  Flagstaff, AZ, USA
  \AND
  \name Guillem Rigaill \email guillem.rigaill@inra.fr \\
  \addr Laboratoire de Math\'ematiques at Mod\'elisation d'Evry (LaMME)\\
  Universit\'e d'Evry Val d'Essonne, INRA\\
  Evry, France
  \AND
  \name Paul Fearnhead \email p.fearnhead@lancaster.ac.uk \\
  \addr Department of Mathematics and Statistics\\
  Lancaster University\\
  Lancaster, UK
  \AND
  \name Guillaume Bourque \email guil.bourque@mcgill.ca\\
  \addr Department of Human Genetics\\
  McGill University\\
  Montr\'eal, Qu\'ebec, Canada}

\editor{TBD}

\maketitle

\begin{abstract}
  Peak detection is a central problem for genomic data, and involves
  segmenting counts of DNA sequence reads that are aligned to
  different locations of a chromosome. The goal is to detect peaks
  with higher counts, and filter out background noise with lower
  counts.  Most existing algorithms for this problem are unsupervised
  heuristics tailored to patterns in specific data types. We propose a
  supervised framework for this problem, using optimal changepoint
  detection models with learned penalty functions. We propose the
  first dynamic programming algorithm that is guaranteed compute the
  optimal solution to changepoint detection problems with constraints
  between adjacent segment mean parameters. We also propose a
  supervised learning algorithm for predicting the crucial penalty
  parameter, which determines the number of segments. We compare our
  algorithm to several baselines in a benchmark of labeled ChIP-seq
  data sets with two different patterns (broad H3K36me3 data and sharp
  H3K4me3 data). Whereas baseline unsupervised methods only provide
  accurate peak detection for a single pattern, our supervised method
  achieves state-of-the-art accuracy in all data sets. The log-linear
  timings of our proposed dynamic programming algorithm make it
  scalable to the large genomic data sets that are now common. Our
  implementation is available in the PeakSegOptimal R package on CRAN.
\end{abstract}

\section{Introduction}

In recent years, high-throughput DNA sequencing technologies have been
improving at a rapid pace, resulting in progressively bigger genomic
data sets. Two common genome-wide assays are ChIP-seq, a genome-wide
assay for histone modifications or transcription factor binding sites
\citep{chip-seq}; and ATAC-seq, an Assay for Transposase-Accessible
Chromatin which measures open chromatin \citep{ATACseq}. These
experiments have been used to characterize the epigenome of samples in
large-scale mapping projects such as ENCODE \citep{ENCODE}. Briefly, each
assay yields a set of DNA sequence reads which are aligned to a
reference genome, and then the number of aligned reads are counted at
each genomic position (Figure~\ref{fig:data-models}). This results in
a vector of non-negative integer counts $\mathbf y\in\ZZ_+^n$ over $n$
positions.

The size $n$ of these aligned read count data depends on the size of contiguous regions on chromosomes in the reference genome. For example, the largest
chromosome in the human genome (hg19) is chr1, which has $n=249,250,621$
bases (distinct positions at which the number of aligned reads is
measured). Analysis of such data thus requires computationally
efficient algorithms which scale to data sets of arbitrarily large
size.

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.8\textwidth]{figure-data-models}
  \vskip -0.5cm
  \caption{ChIP-seq read count data (grey lines) for one sample on a
    subset of chromosome~11. \textbf{Top:} the maximum likelihood
    Poisson model with 5 segment means (horizontal green lines) has
    two up changes followed by two down changes (vertical green
    lines). It does not satisfy the up-down constraint (odd-numbered
    changes must be up, and even-numbered changes must be
    down). \textbf{Bottom:} the up-down constrained model has a lower
    log-likelihood value, but each up change is followed by a down
    change. Odd-numbered segments are interpreted as background noise,
    and even-numbered segments are interpreted as peaks (a short peak
    on the left and a tall peak on the right).}
  \label{fig:data-models}
\end{figure}

Although these read counts can be interpreted as quantitative data,
they are most often interpreted using one of the many available peak
detection algorithms \citep{evaluation2010, rye2010manually,
  chip-seq-bench}. A peak detection algorithm is a binary classifier $c(\mathbf y)\in\{0,1\}^n$
for each genomic position, where peaks are the positive class, and
background noise is the negative class. Importantly, peaks and
background occur in long contiguous segments across the
genome. Typical algorithms from the bioinformatics literature such as
MACS \citep{MACS} and HMCan \citep{HMCan} are unsupervised heuristics with several
parameters that affect peak detection accuracy (window/bin sizes,
p-value thresholds, etc). Although such algorithms are fast for large
data sets, they are typically accurate only for a specific data/pattern type (e.g. MACS works for sharp H3K4me3 but not broad H3K36me3 data)
\citep{HOCKING2016-chipseq}.

Hidden Markov Models (HMMs) with common mean parameters for the peak
or background regions could be used to model such sequence data, but
we do not explore them in this paper for two reasons. First, we have
observed in real ChIP-seq data that background and peak means are not
constant throughout the genome (Supplementary Figure~1), so shared
mean parameters would not be a good fit. Second, inference algorithms
for HMMs are only guaranteed to find a local maximum of the
likelihood; we are more interested in changepoint detection models
with dynamic programming algorithms that can provably compute the
global maximum of the corresponding likelihood.

Recently \citet{cleynen2013segmentation} proposed a Pruned Dynamic
Programming Algorithm (PDPA) for computing the most likely $K$ segment
means (and $K-1$ changepoints) using a Poisson model. This is computed for a range
of segments $K$, which acts as a regularization parameter. Small
values of $K$ result in too few segments/peaks (false negative peak detections, underfitting), and
large values of $K$ result in too many (false positive peak detections, overfitting). Oracle penalties
\citep{cleynen2013segmentation} or learned penalties
\citep{HOCKING-penalties} can be used to select the number of segments
$K$.
Because this model sometimes has several consecutive up
changes, it is non-trivial to interpret in terms of peaks and
background (Figure~\ref{fig:data-models}, top).

To ensure that the segmentation model is interpretable in terms of
peaks and background, \citet{HOCKING-PeakSeg} introduced a Constrained
Dynamic Programming Algorithm (CDPA) for computing a model where up changes are followed by down changes, and vice
versa (Figure~\ref{fig:data-models}, bottom). The model with
$P\in\{0,1,\dots, \}$ peaks has $K=2P+1\in\{1, 3, \dots\}$
segments. These constraints ensure that odd-numbered segments can be
interpreted as background, and even-numbered segments can be
interpreted as peaks.
%In contrast to heuristic algorithms such as MACS and HMCan, PeakSeg has only one parameter that affects peak detection accuracy (the number of segments $K$). 
In a recent comparison study, \citet{HOCKING2016-chipseq} showed that
this algorithm achieves state-of-the-art peak detection accuracy in a
benchmark of ChIP-seq data sets which include both broad
H3K36me3 and sharp H3K4me3 data/patterns. This constrained model is
further justified by the statistical arguments of
\citet{minimax-changepoint}, who show that using shape constraints can
reduce the minimal risk bounds; with these being $O(\log \log n)$ for
estimating changes in mean under a monotone constraint as compared to
$O(\log n)$ without the constraint.

% The approach taken by the PeakSeg algorithm can be formalised as follows. For any given number, $K$,
% of segments we try to find the best segmentation. We define how good a segmentation is by fitting
% a constant mean for each segment of the chromosome, subject to the up-down constraint that
% the segment means alternate between increasing and decreasing. Subject to this constraint we find the
% best choice of segment means to minimize some loss function that measures how close the mean is to each 
% observation. The cost of a segmentation is defined to be the resulting value of this loss summed over 
% all observations. For a sequence of $n$ data points, PeakSeg attempts to search over the $O(n^{K-1})$ 
% possible segmentations to find the one that minimizes this cost. 

\begin{table*}[t!]
  \centering
  \begin{tabular}{r|c|c}
    Constraint & No pruning & Functional pruning \\
    \hline
    None & Dynamic Prog. Algo. (DPA) & Pruned DPA (PDPA) \\
    & Optimal, $O(Kn^2)$ time & Optimal, $O(Kn\log n)$ time\\
    % & \citet{segment-neighborhood} & \\
    % & \citet{optimal-partitioning} & \\
    & \citet{segment-neighborhood}     & \citet{pruned-dp, phd-johnson} \\
    \hline
    Up-down & Constrained DPA (CDPA) & Generalized Pruned DPA (GPDPA) \\
    & Sub-optimal, $O(Kn^2)$ time & Optimal, $O(Kn\log n)$ time\\
    & \citet{HOCKING-PeakSeg} & \textbf{This paper} \\
    \hline
  \end{tabular}
  \caption{Our main contribution is 
the Generalized Pruned Dynamic Programming Algorithm (GPDPA), 
 which uses a functional pruning technique 
    to compute the constrained optimal $K-1$ changepoints 
in a sequence of $n$ data. 
Time complexity is on average, 
in our empirical tests on real ChIP-seq data sets.}
\label{tab:contribution}
\end{table*}

The previously proposed CDPA suffers from two major issues, which we fix in
this paper using a rigorous mathematical analysis of the constrained
maximum likelihood changepoint detection problem. First, the CDPA does
not necessarily compute the globally optimal model, because it does
not accurately account for the constraints (for a detailed
explanation, see Supplementary Figure~2). Second, the time complexity
of analyzing $n$ data points with the CDPA is $O(Kn^2)$. Since this is quadratic in the number of
data points, it can be too slow for use on large genomic data sets
which are now common. In this paper we propose a new algorithm that
resolves both of these issues (Table~\ref{tab:contribution}).

\paragraph{Contributions and Organization.} In
Section~\ref{sec:models} we define the optimal changepoint detection
problems. The first problem is where there are no constraints between the
segment-specific mean parameters. The second
is where we impose the up-down constraint
between the means of neighboring segments. Whilst
several efficient dynamic programming algorithms can solve the
unconstrained minimization, we are unaware of equivalent dynamic
programming algorithms for exactly solving the constrained version.
Our main contribution is described in Section~\ref{sec:algorithms},
where we generalize the functional pruning technique of
\citet{pruned-dp} so that it can be applied to the constrained
minimization problem (Table~\ref{tab:contribution}), leading to the fast and optimal Generalized Pruned Dynamic Programming
Algorithm (GPDPA). 
These new ideas around how to deal with constraints on the means for 
neighbouring segments is of independent interest. For example, since the 
first version of this paper appeared \citep{Hocking-constrained-changepoint-detection}, its ideas have already been used to 
model monotone constraints in spike detection problems for calcium imaging 
data \citep{Jewell2018}.
In Section~\ref{sec:labeled-supervised} we describe the labeled data sets and we propose a supervised learning algorithm for predicting the crucial penalty parameter, which determines the number of segments $K$. In Section~\ref{sec:results} we show that our proposed algorithms
achieve state-of-the-art speed and peak detection accuracy in a
benchmark of ChIP-seq data sets. The paper ends with a
discussion.

\section{Unconstrained and Constrained Changepoint Models}
\label{sec:models}

In this section we define two related changepoint detection
problems. 
We use tilde $\tilde{C}$
to denote the unconstrained cost, and no tilde $C$ to denote the
up-down constrained cost.

\subsection{Unconstrained changepoint model with $K$ segments}

The data consist of $n$ observations denoted by the random vector
$\mathbf y = (y_1, \dots, y_n)$. 
We assume a piecewise constant mean model with
$K-1$ changes ($K$ distinct values). For each segment
$k\in\{1\,\dots,K\}$, the real-valued mean parameter $u_k$ is assigned
to data points $(t_{k-1},t_k]$. The first index, $t_0=0$, and last
index, $t_K=n$, are fixed; the others, $t_1<\cdots<t_{K-1}$, are
changepoint variables. 

For real-valued data $y_t\in\RR$, the statistical model is for every
segment $k\in\{1\,\dots,K\}$, each data point on that segment
$t\in(t_{k-1},t_k]$ is
$y_t\stackrel{\text{iid}}{\sim}N(u_k,\sigma^2)$.  Maximizing the
likelihood in this Normal model is equivalent to minimizing the square
loss $\ell(y_t,u_k)=(u_k-y_t)^2$. In the case of genomic count data,
we have a sequence of non-negative integers $y_t\in\ZZ_+$, so we
assume $y_t\stackrel{\text{iid}}{\sim}\text{Poisson}(u_k)$.
Maximizing the likelihood in the Poisson model is equivalent to
minimizing the Poisson loss $\ell(y_t,u_k)=u_k-y_t\log u_k$. In either
case we can write the cost function for segment $k$ as
\begin{equation}
  \label{eq:h}
  h_{t_{k-1}, t_k}(u_k) = \sum_{\tau=t_{k-1}+1}^{t_k} \ell(y_\tau, u_k)
\end{equation}

The optimal cost in $K$ segments up to $n$ data points
is defined as the solution of the following optimization problem:
\begin{equation}
  \label{eq:segment-neighborhood}
\tilde{C}^*_{K,n} = \min_{\substack{
u_1,\dots, u_{K}\in\RR
\\
0=t_0<t_1<\cdots<t_{K-1}<t_K=n
}}
  \sum_{k=1}^K
h_{t_{k-1}, t_k}(u_k)
\end{equation}
This optimization problem is non-convex because the changepoint
variables $t_k$ are integers. Nonetheless, the optimal solution can be
computed in $O(K n^2)$ time using a dynamic programming algorithm
\citep{segment-neighborhood}. By exploiting the structure of the
loss function $\ell$, the pruned dynamic programming algorithm
of \citet{pruned-dp} computes the same optimal solution much faster;
empirically having a computational cost that is $O(K n \log n)$.
Efficient algorithms exist for solving similar problems such
as Optimal Partitioning
\citep{optimal-partitioning,phd-johnson,pelt,fpop} and the Fused Lasso
\citep{flsa}.


\subsection{Up-down constrained changepoint model with $K$ segments}

The peak detection problem we are interested in can be formulated in a
similar way, but with the addition of further constraints on the
segment means. These constraints force the mean to alternate between
increasing and decreasing at each changepoint. 
Formally, the optimal cost in $K$ segments up to $n$ data points, subject to the up-down constraint, is defined as
\begin{align}
  \label{eq:segment-neighborhood-up-down}
C^*_{K,n} = \min_{\substack{
u_1,\dots, u_{K}\in\RR
\\
0=t_0<t_1<\cdots<t_{K-1}<t_K=n
}} & \ \
  \sum_{k=1}^K
h_{t_{k-1}, t_k}(u_k)\\
      \text{subject to \hskip 0.8cm} &\ \ u_{k-1} \leq u_k\ \forall k\in\{2,4,\dots\},
  \nonumber\\
  &\ \ u_{k-1} \geq u_k\ \forall k\in\{3,5,\dots\}.
  \nonumber
\end{align}
It is worth noting the connection between this up-down constrained
changepoint problem~(\ref{eq:segment-neighborhood-up-down}) and
several related problems that have been previously studied. The
\emph{reduced} isotonic regression problem is similar
\citep{reduced-monotonic-regression}, but uses only non-decreasing
$u_{k-1}\leq u_k$ change constraints for all $k$. \citet{hardwick2014optimal} proposed an efficient algorithm for 
reduced isotonic regression. Note that the well-known
Pool-Adjacent-Violators Algorithm \citep{mair2009isotone} solves a
simpler problem (isotonic regression), without the constraint on the
number of segments $K$.

Our contribution in this paper is proving
that the functional pruning technique of \citet{pruned-dp} and
\citet{fpop} can be generalized to constrained changepoint models such
as (\ref{eq:segment-neighborhood-up-down}). The
resulting Generalized Pruned Dynamic Programming Algorithm (GPDPA)
computes the optimal solution to the up-down constrained changepoint model, and enjoys $O(Kn\log n)$ time complexity (on average in our empirical
tests of real ChIP-seq data sets).

\section{Dynamic programming algorithms for constrained
  changepoint models}
\label{sec:algorithms}

Note in the last section we used a star $C^*\in\RR$ to denote the
scalar optimal cost value. In this section we remove the star
$C:\RR\rightarrow\RR$ to denote the real-valued optimal cost function.


% In this section we propose a Generalized Pruned Dynamic Programming
% Algorithm (GPDPA) that computes the solution to constrained
% changepoint problems. We begin by discussing how to solve a special
% case, the reduced isotonic regression problem
% (\ref{eq:reduced}).


\subsection{Classical dynamic programming approach}

In this section we review the Constrained Dynamic Programming
Algorithm (CDPA), which we previously proposed
\citep{HOCKING-PeakSeg}. The CDPA is a simple modification of the
classical dynamic programming algorithm
\citep{segment-neighborhood}. The classical algorithm recursively
computes the optimal cost in $K$ segments up to $n$ data points via
\begin{eqnarray}
  \tilde{C}^*_{K,n} 
&=& \min_{\substack{
u_1,\dots,u_{K}\in\RR
\\
0=t_0<t_1<\cdots<t_{K-1}<t_K=n
}}
  \sum_{k=1}^K
  h_{t_{k-1}, t_k}(u_k)\\
&=& \min_{t_{K-1}} 
\underbrace{
    \min_{\substack{
    u_1,\dots,u_{K-1}
  \\
  t_1<\cdots<t_{K-2}
  }} \sum_{k=1}^{K-1} h_{t_{k-1},t_k}(u_k)
}_{\tilde{C}^*_{K-1,t_{K-1}}}
+ \underbrace{
  \min_{u_K} h_{t_{K-1,n}(u_K)}
}_{h^*_{t_{K-1},n}}
\label{eq:classic-dp-recursion}
\end{eqnarray}
The main idea of the classical dynamic programming recursion
(\ref{eq:classic-dp-recursion}) is to separate the cost into two
terms. The left term $\tilde{C}^*_{K-1,t_{K-1}}$ is the previously
computed cost of the best model in $K-1$ segments up to data point
$t_{K-1}$. The right term $h^*_{t_{K-1},n}$ is the optimal cost of the
$K$-th segment, which starts after the last changepoint $t_{K-1}$ and
continues until the final data point $n$. The minimization in
(\ref{eq:classic-dp-recursion}) over all possible last changepoints
$t_{K-1}\in\{K-1, \dots, n-1\}$ can be computed in $O(n)$ time. The vector of
$h^*_{K-1,n},\dots,h^*_{n-1,n}$ values can be computed in $O(n)$
time; computing the entire vector of
$\tilde{C}^*_{K,K},\dots,\tilde{C}^*_{K,n}$ is therefore $O(n^2)$ using
(\ref{eq:classic-dp-recursion}). 

\paragraph{Modification for constraints.} In the CDPA we proposed to
constrain the set of possible last changepoints $t_{K-1}$ used in the
minimization (\ref{eq:classic-dp-recursion}). In the right side of
(\ref{eq:classic-dp-recursion}) the min with respect to the last
segment mean $u_K$ is achieved by
\begin{equation}
  \hat u_{t_{K-1},n}=\argmin_{u_K\in\RR} h_{t_{K-1},n}(u_K),
\end{equation}
which is the best mean value for the last segment starting after data
point $t_{K-1}$. The main idea of the CDPA is to only consider last
changepoints $t_{K-1}$ which result in a last segment mean
$\hat u_{t_{K-1},n}$ that jumps in the correct direction (up or
down). More precisely, letting $\mathcal U_{K-1,\tau}$ be the best
mean of the $K-1$-th segment up to data point $\tau$, we consider the
reduced set of possible changepoints
\begin{equation}
\mathcal I_{K,n} = \begin{cases}
\tau\in\{K-1, \dots, n-1\}\mid \mathcal U_{K-1,\tau}< \hat u_{\tau,n} &\text{ if $K$ is even}\\
\tau\in\{K-1, \dots, n-1\}\mid \mathcal U_{K-1,\tau}> \hat u_{\tau,n} &\text{ if $K$ is odd}\\
\end{cases}
\end{equation}
That yields the recursive update rule for the constrained  cost 
\begin{eqnarray}
%\mathcal T_{K,n} &=& \argmin_{\tau\in\mathcal I_{K,n}} 
%\mathcal L_{K-1,\tau}
%+h^*_{\tau,n}\\
\label{eq:cdpa-recursion}
c^*_{K,n} &=& \min_{\tau\in\mathcal I_{K,n}} 
c^*_{K-1,\tau} + h^*_{\tau, n}
%\mathcal L_{K-1,\mathcal T_{K,n}} + h^*_{\mathcal T_{K,n}, n}\\
%\mathcal U_{K,n} &=& u^*_{\mathcal T_{K,n}, n}\\
\end{eqnarray}
Here we use the lowercase $c^*$ notation for the cost to emphasize that this update
rule is a greedy heuristic; it does not always compute the global optimum  $C^*_{K,n}$ of the constrained problem
(\ref{eq:segment-neighborhood-up-down}). Using this update rule, computing the entire matrix of constrained
cost values $c^*_{k,t}$ for all $k\in\{1,\dots, K\}$
and $t\in\{1,\dots,n\}$ takes $O(Kn^2)$ time. We therefore propose a new
update rule in the next section which is both faster and optimal.

\subsection{Dynamic programming with functional pruning}
\label{sec:functional-pruning}

The key insight of
functional pruning is that the order of minimization can be reversed in
(\ref{eq:classic-dp-recursion}). By taking out the minimization with
respect to the last segment mean $u_K$, we obtain the following equation for the optimal cost in $K$ segments up to data point $n$,
\begin{equation}
  \tilde{C}^*_{K,n} = \min_{u_K} \underbrace{\min_{t_{K-1}} 
\tilde{C}^*_{K-1,t_{K-1}}
+  h_{t_{K-1,n}(u_K)}}_{\tilde{C}_{K,n}(u_K)}.
\end{equation}
The idea, originally proposed for the unconstrained problem
\citep{pruned-dp}, is to recursively compute the $\tilde{C}_{K,n}$
functions via
\begin{eqnarray}
\tilde{C}_{K,n}(u_K) 
&=& \min_{\tau\in\{K-1,\dots,n-1\}} \tilde{C}^*_{K-1,\tau} + h_{\tau,n}(u_K)
\\
&=& \ell(y_n, u_K) + \min\{\tilde{C}^*_{K-1,n-1},\, 
\min_{\tau\in\{K-1,\dots,n-2\}} \tilde{C}^*_{K-1,\tau} + h_{\tau,n-1}(u_K)
\}\label{eq:remove-last-data}\\
&=& \ell(y_n, u_K) + \min\{\tilde{C}^*_{K-1,n-1}, \tilde{C}_{K,n-1}(u_K)\}
\label{eq:functional-recursion}
\end{eqnarray}
The equation (\ref{eq:remove-last-data}) is obtained by removing the
cost of the last data point $\ell(y_n, u_K)$ from the terms in the
min. The Pruned Dynamic Programming Algorithm (PDPA) recursion
(\ref{eq:functional-recursion}) states that the functional cost
$\tilde{C}_{K,n}(u_K)$ up to data point $n$ can be computed using the
functional cost $\tilde{C}_{K,n-1}(u_K)$ up to the previous data point
$n-1$.
%This results in a faster algorithm because the $\min\{\}$ operation in the update rule (\ref{eq:functional-recursion}) involves only two terms

\paragraph{Modification for constraints.} 
In this section we present our main contribution, which generalizes the functional pruning technique for the up-down constrained problem~(\ref{eq:segment-neighborhood-up-down}). We begin by defining the functional cost for the up-down constrained problem,
\begin{align}
  \label{eq:segment-neighborhood-up-down-fun}
C_{K,n}(u_K) = \min_{\substack{
u_1,\dots, u_{K-1}\in\RR
\\
0=t_0<t_1<\cdots<t_{K-1}<t_K=n
}} & \ \
  \sum_{k=1}^K
h_{t_{k-1}, t_k}(u_k)\\
      \text{subject to \hskip 0.8cm} &\ \ u_{k-1} \leq u_k\ \forall k\in\{2,4,\dots\},
  \nonumber\\
  &\ \ u_{k-1} \geq u_k\ \forall k\in\{3,5,\dots\}.
  \nonumber
\end{align}
Note that the definition of the optimal cost function above removes
one optimization variable, $u_K$, with respect to the definition of
the optimal cost value
$C^*_{K,n}$~(\ref{eq:segment-neighborhood-up-down}). We have the
following recursion for all $K\geq 2$:
\begin{align}
  \label{eq:segment-neighborhood-up-down-fun-recursion}
C_{K,n}(u_K) = \min_{t_{K-1},u_{K-1}} & \ \ 
  C_{K-1,t_{K-1}}(u_{K-1})+
h_{t_{K-1},n}(u_K)\\
      \text{subject to} &\ \   \begin{cases}
    u_{K-1}\leq u_K  & \text{ if $K$ is even}\\
    u_{K-1}\geq u_K  & \text{ if $K$ is odd}\\
  \end{cases}
  \nonumber
\end{align}
A key new idea of our paper is that the equation~(\ref{eq:segment-neighborhood-up-down-fun-recursion}) can be simplified using the min-less operator:
\begin{definition}[Min-less operator]
\label{def:min-less}
  Given any real-valued function $f:\RR\rightarrow\RR$, we define its min-less
  operator as $f^\leq(\mu)=\min_{x\leq \mu} f(x)$.
\end{definition}
Let us consider the case of $K=2$. The equation~(\ref{eq:segment-neighborhood-up-down-fun-recursion})
simplifies to
\begin{equation}
  \label{eq:segment-neighborhood-up-down-fun-recursion-K2}
C_{2,n}(u_2) = \min_{t_{1}} 
h_{t_{1},n}(u_2)+ \underbrace{
  \min_{u_1\leq u_2} C_{1,t_{1}}(u_{1}) 
}_{C_{1,t_{1}}^\leq(u_2)}
\end{equation}
The min-less operator is used write the cost as a function of a single
segment mean variable $u_2$ (Figure~\ref{fig:compare-unconstrained},
left). Likewise, for odd $K$, we need the min-more operator.
\begin{definition}[Min-more operator]
\label{def:min-more}
  Given any real-valued function $f:\RR\rightarrow\RR$, we define its min-more
  operator as $f^\geq(\mu)=\min_{x\geq \mu} f(x)$.
\end{definition}
The min-less and min-more operators is used in the following
theorem, which states the update rules used in our proposed algorithm.

\begin{theorem}[Generalized Pruned Dynamic Programming Algorithm/GPDPA]
\label{thm:gpdpa}
  The constrained optimal cost functions $C_{K,n}$ can be recursively computed.
\begin{enumerate}
\item For $K=1$ we have
$C_{1,1}(\mu)=\ell(y_1,\mu)$, and for the other data
  points $n>1$ we have
$
C_{1,n}(\mu)=C_{1,n-1}(\mu)+\ell(y_n,\mu),
$
\item For $K>1$ and $n=K$ we have
$
  C_{K,K}(\mu)=\ell(y_K, \mu)+
  \begin{cases}
    C_{K-1,K-1}^\leq(\mu) & \text{ if $K$ is even}\\
    C_{K-1,K-1}^\geq(\mu) & \text{ if $K$ is odd} 
  \end{cases}
$
\item For $K>1$ and $n>K$ we have
 $$
  C_{K,n}(\mu)=\ell(y_n,\mu)+\min\{
C_{K,n-1}(\mu),\,
  \begin{cases}
C_{K-1,n-1}^\leq(\mu)
   & \text{ if $K$ is even}\\
  C_{K-1,n-1}^\geq(\mu)
   & \text{ if $K$ is odd}
  \end{cases}
$$
\end{enumerate}
\end{theorem}

\begin{proof}
  Case 1 and 2 follow from the definition of the constrained
  functional cost~(\ref{eq:segment-neighborhood-up-down-fun}). We prove
  case 3 for even $K$ (the proof for odd $K$ is analogous).  Using the min-less operator (Definition~\ref{def:min-less}), the
  functional cost recursion
   (\ref{eq:segment-neighborhood-up-down-fun-recursion})  
 simplifies to
  \begin{equation}
    C_{K,n}(u_K) 
= \min_{\tau\in\{K-1,\dots,n-1\}}
C_{K-1,\tau}^\leq(u_{K}) + h_{\tau,n}(u_K),
  \end{equation}
  where the right term $h_{\tau,n}(u_K)$ is the cost of the last segment $K$,
  and the left term $C_{K-1,\tau}^\leq(u_{K})$ is the  cost of all previous segments. Taking out the cost of the last data point
    $n$ results in
  \begin{eqnarray}
    C_{K,n}(u_K)&=&\ell(y_n, u_K) + \min
    \begin{cases}
      C_{K-1,K-1}^\leq(u_{K}) + h_{K-1,n-1}(u_K),\, \dots,\\
      C_{K-1,n-2}^\leq(u_{K}) + h_{n-2,n-1}(u_K),\\
      C_{K-1,n-1}^\leq(u_{K})
\label{eq:many-min}
    \end{cases}\\ 
&=& \ell(y_n,u_K) + \min\{
C_{K,n-1}(u_K),\,
C_{K-1,n-1}^\leq(u_{K})
\}.
\label{eq:last-equality}
  \end{eqnarray}
  The final equality~(\ref{eq:last-equality}) is obtained using the
  definition of the constrained functional
  cost~(\ref{eq:segment-neighborhood-up-down-fun}), because
  $C_{K,n-1}(u_K)$ is equivalent to all but the last term in the min
  in~(\ref{eq:many-min}). This proves that the update rules in Theorem~\ref{thm:gpdpa} can be used to recursively compute the constrained optimal functional cost~(\ref{eq:segment-neighborhood-up-down-fun}).
\end{proof}

\begin{figure*}[t!]
  \centering
  \input{figure-compare-unconstrained}
  \input{figure-compare-cost}
  \vskip -0.5cm
  \caption{Comparison of previous unconstrained algorithm
    (\textcolor{Min}{grey}) with new algorithm that constrains segment
    means to be non-decreasing (\textcolor{Ckt}{red}), for the toy data
    set $\mathbf y= [ 2, 1, 0, 4 ] \in\RR^4$ and the square
    loss. \textbf{Left:} rather than computing the unconstrained
    minimum (constant grey function), the new algorithm computes the
    min-less operator (red), resulting in a larger cost when the
    segment mean is less than the first data point ($\mu <
    2$). \textbf{Right:} adding the cost of the second data point
    $(\mu-1)^2$ and minimizing yields equal means $u_1=u_2=1.5$ for
    the constrained model and decreasing means $u_1=2,\, u_2=1$ for
    the unconstrained model.}
  \label{fig:compare-unconstrained}
\end{figure*}

\paragraph{Intuition for speed of functional pruning.} 
In this section we provide a summary of the main ideas of functional
pruning for optimal changepoint detection; for a more complete
discussion we refer the reader to \citep{fpop}. To explain why
the functional pruning approach results in a fast algorithm, we
consider computing $C_{2,n}(u_2)$, the optimal cost up to data point
$n$ with second segment mean $u_2$. Computing this function
via~(\ref{eq:segment-neighborhood-up-down-fun-recursion-K2}) requires
taking the pointwise min of changepoint cost functions
$h_{t_1,n}(u_2)+C_{1,t_1}^\leq(u_2)$ for all possible changepoints
$t_1\in\{1,\dots,n-1\}$.

However, if there is a particular changepoint $t_1$ with a sub-optimal cost $C_{2,n}(u_2)<h_{t_1,n}(u_2)+C_{1,t_1}^\leq(u_2)$ for all $u_2$,
then that changepoint can be pruned (there is no value of the segment
mean $u_2$ for which $t_1$ would be the best choice of the most
recent changepoint). More precisely, let
$\mathcal T_{2,n}=\{ t_1\mid C_{2,n}(\mu)=h_{t_1,n}(\mu)+C_{1,t_1}^\leq(\mu)
\text{ for some $\mu$} \}$ be the set of changepoints which have not
yet been pruned.  Then the optimal cost function can also be computed
by minimizing with respect to this reduced set of changepoints,
\begin{equation}
  C_{2,n}(u_2) = 
\min_{t_1\in\{1,\dots,n-1\}}
h_{t_1,n}(\mu)+C_{1,t_1}^\leq(\mu)
=
\min_{t_1\in\mathcal T_{2,n}}
h_{t_1,n}(\mu)+C_{1,t_1}^\leq(\mu).
\end{equation}
This pruning results in speed improvements because typically the
number of candidate changepoints $|\mathcal T_{2,n}|$ is much smaller
than $n$. For example in Figure~\ref{fig:min-envelope}, pruning at
data point $35$ results in only one candidate changepoint. In
Section~\ref{sec:results_time}, we show that the empirical number of
candidate changepoints in real ChIP-seq data sets is $O(\log n)$.

\begin{figure*}[t!]
  \centering
  \input{figure-2-min-envelope}
\vskip -1cm
  \caption{
% Computing the optimal cost functions $C_{3,t}(u_3)$ subject
%     to the constraint $u_3\leq u_2$. \textbf{Left:} the pruning at
%     $t=34$ takes the minimum of the cost of a non-increasing change
%     after data point $t=34$ ($C_{2,34}^\geq$) to the cost of a change
%     before ($C_{3,34}$). \textbf{Middle:} the optimal cost up to
%     $t=35$ is defined as the cost of the new data point
%     $\ell_{35}(u_3)=\ell(y_{35},u_3)$ plus the minimum of the previous
%     pruning step $M_{3,34}=\min\{C_{3,34},
%     C_{2,34}^\geq\}$. \textbf{Right:} because
%     $C_{2,34}^\geq(u_3)<C_{3,35}(u_3)$ for all mean values $u_3$, all
%     previous changepoints can be pruned, resulting in an optimal cost
%     $M_{3,35}=\min\{C_{3,35},C_{2,35}^\geq\}=C_{2,35}^\geq$ with only
%     two intervals.
% (one constant, one convex).
    % The cost $C_{k,t}$ of the PeakSeg model~(\ref{eq:PeakSeg-non-strict}) in $k$
    % segments up to data point $t$ is computed using the min
    % $M_{k,t-1}$, which prunes intervals with sub-optimal cost (black
    % dots show interval limits). 
    Demonstration of GPDPA for the up-down constrained model
    with $3$ segments. Cost functions are stored as piecewise
    functions on intervals (black dots show limits between function
    pieces; each function piece represents a candidate changepoint). 
    \textbf{Left:} the min \textcolor{Min}{$M_{3,34}$} is the
    minimum of two functions: \textcolor{MinMore}{$C^{\geq}_{2,34}$}
    is the cost if the second segment ends at data point $t=34$ (the
    min-more operator forces a non-increasing change after), and
    \textcolor{Ckt}{$C_{3,34}$} is the cost if the second segment ends
    before that. \textbf{Middle:} the cost \textcolor{Ckt}{$C_{3,35}$}
    is the sum of the min \textcolor{Min}{$M_{3,34}$} and the cost of
    the next data point \textcolor{Data}{$\ell_{35}$}. \textbf{Right:}
    in the next step, all previously considered changepoints are
    pruned (cost \textcolor{Ckt}{$C_{3,35}$}), since the model with the second
    segment ending at data point $t=35$ is always less costly
    (\textcolor{MinMore}{$C^{\geq}_{2,35}$}).  }
  \label{fig:min-envelope}
\end{figure*}

\subsection{Implementation and computational complexity}
\label{sec:implementation}

To implement the Generalized Pruned Dynamic Programming Algorithm
(GPDPA), we use an exact representation of the
$C_{k,t}:\RR\rightarrow\RR$ cost functions. Each $C_{k,t}(\mu)$ is
represented as a piecewise function on intervals of $\mu$, one
interval for each candidate changepoint. This is implemented as a
linked list of FunctionPiece objects in C++ (for details see
Supplementary Text 1). Each element of the linked list represents a
convex cost function piece, and implementation details depend on the
choice of the loss function $\ell$ (for an example using the square
loss see Section~\ref{sec:example-comparison}). Importantly, the
min-less $C_{k,t}^\leq$ and min-more $C_{k,t}^\geq$ operators (Definitions~\ref{def:min-less} and \ref{def:min-more}) can be efficiently computed using this
representation.

% Whilst each
% $C_{k,t}(\mu)$ is defined for $\mu \in \RR$, we can show that the
% optimal choice of any segment mean must lie within the range of the
% data. Thus we first calculate the minimum and maximum of the data and
% then only calculate each $C_{k,t}(\mu)$ for $\mu$ between these two
% values.

The functional pruning is accomplished by the
$\min\{\}$ operation in update rule~3 of Theorem~\ref{thm:gpdpa}. For example if $k$ is even, $C_{k-1,t-1}^\leq(\mu)$ is the cost if segment $k-1$
ends on data point $t-1$, and $C_{k,t-1}(\mu)$ is the cost of a
changepoint before that. In the $\min\{\}$ operation, these two
functions are compared, and pruning occurs for any cost function
pieces (candidate changepoints) which are sub-optimal for all $\mu$.
For example the right panel of Figure~\ref{fig:min-envelope} shows a
data set for which all previous changepoints are pruned at $t=35$.

We implemented the GPDPA using the Poisson loss
$\ell(y, \mu) = \mu - y\log \mu$, since our application in
Section~\ref{sec:results-chip-seq} is on ChIP-seq non-negative count data
$y\in\ZZ_+ = \{0, 1, 2, \dots\}$.
Our free/open-source C++ implementation is
available as the PeakSegPDPA function in the PeakSegOptimal R package
on
CRAN.\footnote{\url{https://cran.r-project.org/package=PeakSegOptimal}}
Implementation details can be found in Supplementary Text 1.

The GPDPA requires
computing $O(Kn)$ cost functions $C_{k,t}$. As in the original
pruned dynamic programming algorithm \citep{pruned-dp}, the average time
complexity of the GPDPA is $O(K n I)$ where $I$ is the average number of
intervals (convex function pieces; candidate changepoints) that are
used to represent a cost function. For the unconstrained problem, the theoretical maximum number of
intervals is $I=O(n)$, implying a worst case time complexity of $O(K n^2)$
\citep{pruned-dp-new}.
% However, this maximum is only achieved in
% pathological synthetic data sets, such as a monotonic increasing data
% sequence. The average number of intervals in real data sets is
% empirically $I=O(\log n)$, as we will show in
% Section~\ref{sec:results_time}. Thus the average empirical time
% complexity of the algorithm is $O(K n \log n)$.
For the up-down constrained problem the theoretical maximum number of intervals is unknown, but in practice we have always observed $I\ll n$. For example,
we investigate the empirical computational cost for the
up-down constrained algorithm in Section~\ref{sec:results_time} and observe $I=O(\log n)$, which corresponds to an overall average computational cost that
is $O(Kn\log n)$.

\subsection{Example and comparison with unconstrained case}
\label{sec:example-comparison}

In this section we show our proposed algorithm for constrained
changepoint detection differs from the previous unconstrained
algorithm. We show the first few steps of the GPDPA for the toy data
set $\mathbf y= \left[
\begin{array}{cccccc}
  2 & 1 & 0 & 4
\end{array}
\right] \in\RR^4$ and the square loss $\ell(y,\mu)=(y-\mu)^2$. The first
step of the algorithm is to compute the minimum and the maximum of the
data (0,4) in order to bound the possible values of the segment
mean $\mu$. Then the algorithm computes the optimal cost in $1$ segment up
to data point $1$:
\begin{equation}
  C_{1,1}(u_1) = (2-u_1)^2=4 - 4u_1 + u_1^2\text{ (for $u_1\in[0,4]$)}
\end{equation}
This function can be stored for all values of $u_1$ via the three
real-valued coefficients ($\text{constant}=4$, $\text{linear}=-4$,
$\text{quadratic}=1$). We then compute the cost of a new segment with
a non-decreasing mean after the first data point (red curve on left of
Figure~\ref{fig:compare-unconstrained}),
\begin{equation}
  C_{1,1}^\leq(u_2) =
%\min_{u'\leq u}C_{1,1}(u')=
  \begin{cases}
    4 - 4 u_2 + u_2^2 &\text{ if }u_2\in[0,2],\, u_1=u_2,\\
    0 + 0 u_2 + 0 u_2^2 & \text{ if }u_2\in[2,4],\,  u_1=2.
  \end{cases}
\end{equation}
This function can be stored as a list of two intervals of mean
values, each with associated real-valued coefficients. To facilitate
recovery of the optimal parameters, we also store the previous segment
mean $u_1$ and endpoint (for details see Supplementary
Text 1). Note that the first interval represents the cost of an
active equality constraint ($u_1=u_2$) and the second interval
represents the cost of a change up ($2=u_1<u_2$). In the unconstrained
algorithm we would have computed the constant cost of any change (up
or down) after the first data point, $\min_{u_1} C_{1,1}(u_1) =0$
(grey curve on left of Figure~\ref{fig:compare-unconstrained}).

By adding the cost of a non-decreasing change after the first data
point $C_{1,1}^\leq(u_2)$ to the cost of the second data point
$(u_2-1)^2$ we obtain the optimal cost in $2$ segments up to data
point $2$,
\begin{equation}
  C_{2,2}(u_2) = 
%C_{1,1}^\leq(u)+(1-u)^2 = 
  \begin{cases}
    5 - 6 u_2 + 2 u_2^2 &\text{ if }u_2\in[0,2],\,  u_1=u_2,\\
    1 - 2 u_2 + 1 u_2^2 &\text{ if }u_2\in[2,4],\,  u_1=2.
  \end{cases}
\end{equation}
Note that the minimum of this function is achieved at $\mu=1.5$ which
occurs in the first of the two function pieces (red curve on right of
Figure~\ref{fig:compare-unconstrained}), with an equality constraint
active. This implies the optimal model up to data point $2$ with
$2$ non-decreasing segment means actually has no change
($u_1=u_2=1.5$). In contrast, the minimum of the cost computed by the
unconstrained algorithm is at $u_2=1$ (grey curve on right of
Figure~\ref{fig:compare-unconstrained}), resulting in a change down
from $u_1=2$.


\subsection{Simple data for which GPDPA is optimal
  but CDPA is not} 

The CDPA update rule (\ref{eq:cdpa-recursion}) is a heuristic for
solving the up-down constrained problem~(\ref{eq:segment-neighborhood-up-down}) because it is not
guaranteed to compute the optimal solution. In this section we discuss
two illustrative examples for which the CDPA does not compute the optimal
solution, but our proposed GPDPA does.

For the set of four data points [1, 10, 14, 13] the CDPA fails to recover
the optimal solution for $K=3$ segments. In fact, the CDPA returns no
model when run in the forward direction on this data set, and a
sub-optimal model [5.5, 5.5, 14, 13] with Poisson loss of
$\approx -51.04$ when run in the backward direction. In contrast, our
proposed GPDPA returns the optimal model [1, 37/3, 37/3, 37/3 ] which
has Poisson loss of $\approx -54.96$. Note that the equality
constraint $u_2=u_3$ is active between the second and third segment
means. This implies that the optimal model with strict inequality
constraints $u_2>u_3$ is undefined, i.e. $\forall \epsilon>0,\, [1, 37/3
+ \epsilon, 37/3 + \epsilon, 37/3 - \epsilon]$ is not optimal because
$[1, 37/3 + \epsilon/2, 37/3 +\epsilon/2, 37/3 - \epsilon/2]$ has a
lower cost.

There are also data sets for which an optimum that satisfies the
strict inequality constraints exists, but the CDPA does not recover
it. See Supplementary Figure 2 for a detailed discussion of the 
set of six data points [3, 9, 18, 15, 20, 2], for which the CDPA returns no model with
$K=5$ segments. For these data, the optimal model [6, 6, 18, 15, 20,
2] satisfies the strict inequality constraints, and is computed by our
proposed GPDPA.

\section{Labeled data and supervised learning algorithm}
\label{sec:labeled-supervised}

The real data analysis problem that motivates this work is the
detection of peaks in ChIP-seq data \citep{practical},
% ChIP-seq
% data measure histone modification or transcription factor binding
% throughout a genome, and are typically represented as a vector of
% non-negative counts $\mathbf y\in\ZZ_+^n$ of aligned sequence reads
% for $n$ continguous bases in a genome. 
% Because the typical
% ``coverage'' profile counts a sequence read at each genomic position
% where it aligns, the data usually have spatial correlation, but this
% does not significantly affect the peaks detected by our method (see
% Supplementary Figure 3). This is consistent with theoretical results
% of \citet{Lavielle-Moulines} which suggest that correlated noise does
% not have a large effect on changepoint model estimates (a larger
% penalty compensates for the spatial correlation). 
% Typical data sizes are
% between $n=10^5$ (maximum of the benchmark we consider) and $n=10^8$
% (largest region with no gaps in the human genome hg19). Algorithms
% with sub-quadratic time complexity are thus essential for the analysis
% of such large data sets.
%The main challenge in ChIP-seq data analysis is peak detection, 
which
is essentially partitioning a noisy count data vector $\mathbf y\in\ZZ_+^n$ into peaks and
background. Thus a peak detector can be represented as a function
$c(\mathbf y)\in\{0,1\}^n$ for binary classification at every base
position. The positive class is peaks (genomic regions with large
values, representing protein binding or modification) and the negative
class is background noise (small values).

\begin{figure*}[t!]
  \centering
  \includegraphics[width=\textwidth]{figure-good-bad}
\vskip -0.5cm
\caption{Labels from a biologist (colored rectangles) are used to 
  quantify peak detection error rate, by counting the
  number of incorrectly predicted labels
  (each noPeaks label with an overlapping
  peak is a false positive; each peakStart/End label requires exactly
  one peak start/end in that region, zero starts/ends is a false
  negative, and two or more starts/ends is a false positive).
  \textbf{Left}: a \textcolor{good}{good} model with two peaks results in 0 errors; a
  \textcolor{bad}{bad} model with one large peak results in three errors (two false negatives and one false positive).
  \textbf{Right}: a \textcolor{good}{good} model with two peaks results in 0 errors; a
  \textcolor{bad}{bad} model with three peaks results in five errors (three false negatives and two false positives).
}
  \label{fig:good-bad}
\end{figure*}

\subsection{Peak region labels for genomic data sets}

More specifically, we consider the \emph{supervised} peak detection problem,
in which the peak prediction algorithm can be trained using manually
determined labels that indicate presence/absence of peaks
\citep{HOCKING2016-chipseq}. In this context, a data set
consists of $M$ problems $\mathbf y_1,\dots,\mathbf y_M$
along with labels $L_1,\dots, L_M$ that identify genomic regions with
and without peaks (Figure~\ref{fig:good-bad}). 
These labels can be
used to compute an error rate $E[c(\mathbf y_m), L_m]$ which is the
total of false positives (labels with too many predicted peaks) plus
false negatives (labels with not enough predicted peaks) for a given
labeled data vector $m$. Ideal peak predictions would yield zero
incorrect labels (for example see Figure~\ref{fig:good-bad}).


\subsection{Supervised learning algorithm 
for predicting the penalty}
\label{sec:supervised}

For the optimal changepoint detection algorithms (CDPA, PDPA, GPDPA),
predicting peaks simplifies to selecting the number of
segments/changepoints. For a given problem $m$, let
$\mathbf y_m\in\ZZ_+^{n_m}$ be the data, let
$\mathbf{\hat y}_m^k\in\RR^{n_m}$ be the mean vector with $k$
segments computed via dynamic programming, and let $\ell(\mathbf y_m, \mathbf{\hat y}^k_m)$ be the
total Poisson loss (summed over all $n_m$ data). We use the following
function to select the number of segments for a given
problem $m$ and non-negative penalty parameter $\lambda$:
\begin{equation}
  \kappa_m(\lambda)=\argmin_{k} \ell(\mathbf y_m, \mathbf{\hat y}^k_m)
+ \lambda \mathcal C(\mathbf{\hat y}^k_m),
\end{equation} 
where $\mathcal C$ is a function that measures model complexity. We consider using the simple linear model complexity function $\mathcal C(\mathbf{\hat y}^k_m)=k$ as well as the oracle model complexity
proposed by \citet{cleynen2013segmentation},
\begin{equation}
\label{eq:oracle}
\mathcal C(\mathbf{\hat y}^k_m) =
k\left(
1 + 4\sqrt{1.1 + \log( n_m/k)}
\right)^2.
\end{equation}
The oracle model complexity is motivated by a statistical argument that assumes a piecewise constant Poisson model, but
the constants (4, 1.1) may be sub-optimal in real data that do not satisfy these assumptions. 

We also investigate learned penalty functions.  The main idea of penalty learning \citep{HOCKING-penalties} is to
computed a fixed feature vector $\mathbf x_m\in\RR^d$ for each problem
$m$, then learn a function $f(\mathbf x_m)\in\RR$ that predicts
problem-specific $\log\lambda$ values:
\begin{equation}
  \label{eq:learn-f}
  \minimize_{f}
  \sum_{m=1}^M E\left[
    c(\mathbf y_m, \kappa_m(\exp f(\mathbf x_m))), 
    L_m\right],
\end{equation}
where $c(\mathbf y_m, k)\in\{0,1\}^{n_m}$ is the peak prediction
vector for the model with $k$ segments. The goal in~(\ref{eq:learn-f})
is to find the penalty function $f$ that minimizes the total number of
incorrect labels. This problem is non-convex, so we learn $f$ using
the L1-regularized linear model and convex relaxation previously
described \citep{HOCKING-penalties}. We used $d=365$ features which
depend on the data size $n_m$, mean, standard deviation, quantiles,
etc. Specifically, we used the penaltyLearning R
package to compute the feature matrix and learn the L1-regularized
linear model.

To compare with a baseline, we also consider learning a constant
function $f(\mathbf x_m)=\log\lambda$ for all problems $m$:
 \begin{equation}
  \label{eq:learn-lambda}
  \minimize_{\lambda}
  \sum_{m=1}^M E\left[
    c(\mathbf y_m, \kappa_m(\lambda)), 
    L_m\right].
\end{equation}
In this case we perform the minimization using grid search over 200 $\lambda$
values evenly placed on the log scale between $10^{-2}$ and $10^{4}$.

% where $\mathcal K_m$ is the set of models which are feasible for the
% strict inequality constraints, $\mathbf{\hat y}^k_m$ is the estimated
% mean vector with $k$ segments, and $\lambda$ is a non-negative penalty
% constant that controls the false positive rate (larger penalties
% result in fewer peaks and thus fewer false positives). For a given
% constant $\lambda$, let $c^{K_m^\lambda}(\mathbf y_m)\in\{0,1\}^{n_m}$
% be the predicted peak vector. The problem thus simplifies to learning
% a scalar penalty constant $\lambda$ (which is varied in order to
% compute ROC/AUC),
% \begin{equation}
%   \label{eq:learn-lambda}
%   \minimize_{\lambda}
%   \sum_{i=1}^m E\left[
%     c^{K_m^\lambda}(\mathbf y_m), 
%     L_m\right].
% \end{equation}
% We performed the minimization in
% (\ref{eq:learn-lambda}) via grid search (compute the total training error $E$
% for a grid of $\lambda$ values, then choose the value which results in
% the minimum). Multi-parameter affine penalty functions could further
% increase prediction accuracy \citep{HOCKING-penalties}, but we
% observed that learning a single penalty constant is sufficient for
% state-of-the-art accuracy in these data sets
% (Figure~\ref{fig:test-error-dots}). Another reason for using grid
% search is that we wanted to perform a fair comparison with two
% baseline methods from the bioinformatics literature, which we also
% trained using grid search.

% \subsection{Evaluation of peak predictions using labels}

% We consider two accuracy metrics based on the labels in 4-fold
% cross-validation experiments. First we use percent test accuracy,
% which is the percentage of correctly predicted labels in the test
% set. Second, we use the area under the ROC curve (AUC) for the test
% labels. This
\section{Results on peak detection in ChIP-seq data}
\label{sec:results-chip-seq}
\label{sec:results}

\subsection{Benchmark data set}

The seven labeled ChIP-seq data sets that we consider in this paper were originally
described by \citet{HOCKING2016-chipseq}, and are freely available on
the
web.\footnote{\verb|http://members.cbio.mines-paristech.fr/~thocking/chip-seq-chunk-db/|}
Data set names (e.g. Broad H3K36me3 AM immune) indicate
experiment/pattern type (Broad H3K36me3), labeler (AM), and cell types
(immune). The data consist of two different experiment types, H3K4me3
and H3K36me3. H3K4me3 is a histone modification which typically has a
sharp peak pattern (10--20kb peaks). H3K36me3 is a different histone
modification which typically has a broad peak pattern with longer
peaks (see Figure~\ref{fig:good-bad}). Both types of peaks are of
biological interest because they indicate genomic regions with active
genes \citep{histone-review}. For each experiment there are several samples of different
cell types (e.g. the H3K36me3 AM immune data set consists of 15 tcell
samples, 5 monocyte samples, and 1 bcell sample). Accurate peak
detection in these data is important in order to characterize active
regions in each sample and cell type (e.g. H3K36me3 peak predicted at
a particular genomic region in tcell but not in monocyte samples).
Labels in these data were determined
by an expert biologist, who used visual inspection of the data to
determine presence or absence of significant peaks in particular
genomic regions. 
% It has been shown that these types of labels are
% quite stable, and do not change much, even if we change the expert who
% determines the labels \citep{HOCKING2016-chipseq}. 

\subsection{Algorithms to compare and rules for defining peaks}
\label{sec:algos-rules}
We used the following changepoint detection algorithms to compute
models with $K\in\{1,\dots,19\}$ segments (0 to 9 peaks) on each of
the 2752 labeled ChIP-seq data sets:
\begin{description}
\item[Generalized Pruned Dynamic Programming Algorithm (GPDPA)]
  Proposed algorithm that computes the optimal solution to the up-down
  constrained problem~(\ref{eq:segment-neighborhood-up-down}). R
  package PeakSegOptimal. 
\item[Pruned Dynamic Programming Algorithm (PDPA)] Baseline that
  computes the optimal solution to the unconstrained
  problem~(\ref{eq:segment-neighborhood}). R package Segmentor3IsBack.
\item[Constrained Dynamic Programming Algorithm (CDPA)] Baseline that
  computes an approximate solution to the up-down constrained
  problem~(\ref{eq:segment-neighborhood-up-down}). R package PeakSegDP.
\end{description}
\begin{figure} 
  \centering
  \input{figure-infeasible-error}
  \vspace{-1cm} 
  \caption{For piecewise constant mean models (dark blue) with
    active equality constraints, two different rules are used to define
    peaks (light blue). \textbf{Join:} segments adjacent to each equality
    constraint are joined to form a single peak. \textbf{Remove:}
    segments adjacent to each equality constraint are removed from the
    list of predicted peaks. }
  \label{fig:infeasible-error}
\end{figure}
Although in the up-down constrained
model~(\ref{eq:segment-neighborhood-up-down}), all even-numbered
segments are supposed to be peaks (with a change up before and a
change down after), it is possible that an equality constraint is
active (with an equal segment mean before or after). One real data
example of this is shown in Figure~\ref{fig:infeasible-error}, which
effectively has two consecutive up changes for models with
$K\in\{7,9\}$ segments. The unconstrained
problem~(\ref{eq:segment-neighborhood}) also may result in a model
with several consecutive up changes (Figure~\ref{fig:data-models}). In general, when the model does
not satisfy the strict up-down constraints, we consider three rules for
defining the predicted peaks:
\begin{description}
\item[Join] Peaks are defined by joining segments with
  active equality constraints. Equivalent
  to defining background on every segment with a change down before
  and a change up after; and defining peaks everywhere else.
\item[Remove] A peak is removed if it occurs on a segment with an
  active equality constraint. Equivalent to defining a peak on every
  segment with a change up before and a change down after; and
  defining background everywhere else.
\item[Ignore] Completely ignore any model that contains at least one
  infeasible change (active equality constraints or consecutive
  changes in the same direction).
\end{description}
Examples of peaks defined using these rules are shown in
Figure~\ref{fig:infeasible-error}. Note that the Ignore rule would
only consider peak models with $K\in\{3,5\}$ segments in these data,
because the other $K$ have active equality constraints.

We additionally compare with two unsupervised baseline algorithms from the
bioinformatics literature. 
\begin{description}
\item[MACS] is a heuristic algorithm with unknown time complexity from
  the bioinformatics literature \citep{MACS}. We consider it as a
  baseline because it has been shown to achieve state-of-the-art peak
  detection accuracy for sharp H3K4me3 histone mark data
  \citep{HOCKING-PeakSeg}. We computed peaks using 53 different qvalue
  parameters from 0 (few peaks) to 0.8 (many peaks). We kept other parameters at default values.
\item[HMCanBroad] is a another heuristic algorithm with unknown time
  complexity \citep{HMCan}. We consider it as a baseline because it
  has been shown to achieve state-of-the-art peak detection accuracy
  for broad H3K36me3 histone mark data \citep{HOCKING-PeakSeg}. We
  computed peaks using 112 different finalThreshold parameters from
  $10^{-10}$ (few peaks) to $10^5$ (many peaks). We used
  mergeDistance=1000 (recommended by authors for broad peaks), and
  kept other parameters at default values.
\end{description}

\subsection{GPDPA is more often feasible/optimal than other changepoint algorithms}

In this section we compare the changepoint algorithms (PDPA, CDPA,
GPDPA) in terms of optimality and feasibility for the up-down
constrained segmentation problem (with strict inequality constraints).
For each of the 2752 labeled count data vectors, we attempt to compute
models with 0, ..., 9 peaks, so there are a total of 27520 possible
models for each algorithm.

The heuristic CDPA computed the most feasible models
(27469/27520=99.8\%), followed by our proposed GPDPA
(21278/27520=77.3\%), and the unconstrained PDPA computed the fewest
(8106/27520=29.4\%). The heuristic CDPA was sub-optimal for 7246/27520 = 26.3\%
models (the proposed GPDPA was used to compute the optimal solution). 
For 1032/7246 of these, the optimal solution was feasible for the
strict inequality constraints, and was computed by our proposed GPDPA
but not the unconstrained PDPA. 
These results suggest that in ChIP-seq data
sets, our proposed GPDPA is more accurate than the heuristic CPDA, in terms of the Poisson likelihood. 
Furthermore, these results suggest
that GPDPA is more useful than the unconstrained PDPA, since there are
many cases for which PDPA does not compute models that are feasible
for the strict up-down inequality constrants (but GPDPA does).
%Numbers come from figure-PDPA-cDPA-compare.R 

% \subsection{Minimum train error in ChIP-seq data}

% We quantified the minimum train error for each optimal segmentation
% algorithm for each of the 2752 problems, by selecting the number of
% peaks $p\in\{0, ..., 9\}$ which had the minimum number of incorrect
% labels (total error = false positives + false negatives). As suggested
% by \citet{HOCKING2016-chipseq}, the baseline MACS algorithm was
% trained by varying the qvalue parameter between 0 and 0.8, and the
% baseline HMCanBroad algorithm was trained by varying the
% finalThreshold parameter between $10^{-10}$ and $10^5$.

% The minimum train error for each algorithm is shown in
% Table~\ref{tab:min-train-error}. The algorithm with the smallest
% minimum train error was PeakSegDP (677/12826=5.3\%), followed by coseg
% (789/12826=6.2\%). The other algorithms had much larger minimum train
% error rates (10.1\%--21.7\%). These results suggest that the new coseg
% algorithm can find segmentation models which are nearly as accurate as
% the previous state-of-the-art PeakSegDP method.


\subsection{GPDPA fits labels better than baselines in terms of minimum train error}
\label{sec:min-train-error}

In the last section we examined how the algorithms fit the data sets
using the Poisson loss. However the more important
measure of fit in these benchmark data is the number of incorrect
labels $L_m$. We used the labels to compare the algorithms in terms of
minimum train error, as follows.
For each problem $m$, and a given algorithm $A$, we computed a
sequence of $P$ peak models
$c^A_1(\mathbf y_m),\dots,c^A_P(\mathbf y_m)$ (varying number of
segments $K$ for changepoint algorithms, qvalue/finalThreshold for
baselines). For each problem $m$ and peak model $p\in\{1,\dots,P\}$,
we computed the number of incorrect labels
$E[c^A_p(\mathbf y_m), L_m]$. For each problem $m$ we then compute the
minimum incorrect labels over all parameters,
$E^A_m=\min_p E[c^A_p(\mathbf y_m), L_m]$. 

An algorithm $A$ with a perfect fit to the labels would be able to
achieve $E^A_m=0$ errors for each problem $m$. This is not always
possible in real data, due to the distribution of the labels, and the
definition of the models. However, we were interested to determine
which algorithms were able to achieve the fewest number of incorrect
labels. In order to determine which algorithms were best able to fit
the labels, we therefore compare the distribution of min error differences
$E_m^a-E_m^A$ between pairs of algorithms $a,A$ in
Figure~\ref{fig:PDPA-infeasible-error-compare}. Each comparison shown
results in a statistically significant difference ($\text{p-value}<10^{-4}$,
two-sided paired Wilcoxon signed rank test).
% from figure-PDPA-infeasible-error-compare.R
%                   Comparison      p.wilcox       p.prop     p.skellam
% 1: GPDPA-PDPA\n(Remove rule)  1.951843e-68 2.949422e-36  1.088183e-33
% 2:   GPDPA-PDPA\n(Join rule)  1.191972e-62 2.780887e-28  2.445545e-26
% 3: GPDPA-PDPA\n(Ignore rule)  2.493754e-90 2.997466e-60  1.456916e-54
% 4:        GPDPAremove-MACS\n  3.512020e-43 1.773443e-53  3.180890e-49
% 5:  GPDPAremove-HMCanBroad\n 4.472252e-199 0.000000e+00 7.967436e-284
% 6:        GPDPAremove-CDPA\n  2.248093e-05 3.222532e-01  3.281037e-01
% 7:        Remove-Join\nGPDPA  4.630299e-05 3.222532e-01  3.281037e-01
% 8:        Join-Ignore\nGPDPA  4.415176e-16 2.830037e-03  3.594214e-03

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figure-PDPA-infeasible-error-compare}
  \vspace{-1cm}
  \caption{Distribution of differences in min label error among the
    2752 labeled segmentation problems in the ChIP-seq benchmark. 
    \textbf{Top:} up-down constrained GPDPA is more accurate than
    unconstrained PDPA. \textbf{Middle:} GPDPA with Remove
    rule is more accurate than baseline methods MACS, HMCanBroad,
    CDPA. \textbf{Bottom:} Remove rule is more accurate than 
    Join, which is more accurate than Ignore.}
  \label{fig:PDPA-infeasible-error-compare}
\end{figure} 



Because it enforces the up-down constraints, we expected the GPDPA to
be more accurate than the unconstrained PDPA. In agreement with our
expectation, we observed that the up-down constrained GPDPA is indeed
more accurate than the unconstrained PDPA (top panel of
Figure~\ref{fig:PDPA-infeasible-error-compare}), using
any of the three peak definition rules (Ignore, Join, Remove). This is
strong evidence that the up-down constraint is essential for accurate
peak detection.

We expected the GPDPA to be just as accurate as the CDPA, and more
accurate than the other baselines. In fact, we observed that the
proposed GPDPA (with Remove rule) is generally more accurate than all
the other algorithms (MACS, HMCanBroad, CDPA, middle panel of
Figure~\ref{fig:PDPA-infeasible-error-compare}). The largest
difference was for HMCanBroad (GPDPA better for 1219 problems, no
difference for 1494 problems, HMCanBroad better for 39 problems). The
smallest difference was for CDPA (GPDPA better for 48 problems, no
difference for 2689 problems, HMCanBroad better for 39 problems). Overall these data provide strong evidence that the proposed GPDPA detects peaks more
accurately than previous baseline algorithms.

When the GPDPA model has active equality constraints, we proposed
three rules for defining peaks (Ignore, Remove, Join, as discussed in
Section~\ref{sec:algos-rules}), and we did not have any expectation as
to which of these rules would be most accurate in real data. We
observed that the Join rule is always at least as accurate as the
Ignore rule (bottom panel of
Figure~\ref{fig:PDPA-infeasible-error-compare}), which indicates that
the Ignore rule should not be used in practice. Furthermore we
observed that Remove is more accurate than Join (Remove better for 51
problems, no difference for 2683 problems, Join better for 18
problems). These data suggest that the Remove rule should be used for
accurate peak detection when the GPDPA solution contains active
equality constraints. So for the computational cross-validation
experiments in the next sections, we used the Remove rule.

% \begin{table}
%   \centering
%   \input{PDPA-infeasible-error-compare}
%   \caption{Comparison}
%   \label{tab:min-train-error}
% \end{table}




\begin{figure*}[t!]
  \centering
  \parbox{0.49\textwidth}{
    %\input{figure-PDPA-intervals-small}
    \input{figure-PDPA-intervals-log-log}
  }
  \parbox{0.49\textwidth}{
    \input{figure-PDPA-timings-log-log}
    %\input{figure-PDPA-timings-small} 
  }
  \vskip -0.5cm
  \caption{Empirical speed analysis on 2752 count data vectors from
    the histone mark ChIP-seq benchmark. For each vector we ran the
    GPDPA with the up-down constraint and a max of $K=19$
    segments. The expected time complexity is $O(KnI)$ where $I$ is
    the average number of intervals (function pieces; candidate
    changepoints) stored in the $C_{k,t}$ functions. \textbf{Left}:
    number of intervals stored is $I=O(\log n)$ (median,
    inter-quartile range, and maximum over all data sets of a given
    size $n$).  \textbf{Right}: GPDPA time complexity is $O(n\log n)$  (median
    line and min/max band).}
  \label{fig:timings}
\end{figure*}


% \begin{description}
% \item[Segmentor3IsBack::Segmentor] is an implementation of a
%   functional pruning algorithm for computing the solution to the
%   Segment Neighborhood (\ref{eq:optimal_segment_neighborhood}) problem
%   \citep{Segmentor}. Its average time complexity is $O(n \log n)$,
%   and the solution may or may not obey the up-down constraints on
%   segment means. If it does not, then the model is not directly
%   interpretable in terms of peaks (segments after up changes) and
%   background (segments after down changes), so we discard the model.
% \item[PeakSegDP::cDPA] implements a heuristic algorithm with $O(n^2)$
%   time complexity which attempts to solve the up-down
%   constrained problem \citep{HOCKING-PeakSeg}. Models computed by this
%   algorithm are guaranteed to satisfy the up-down constraint, but may
%   not be the optimal solution to the up-down constrained problem
%   (\ref{eq:min_PeakSeg}).
% \item[coseg::PeakSegPDPA] is our proposed solver for the PeakSeg
%   problem, described in Section~\ref{sec:PeakSeg}. It recovers the
%   optimal solution to the up-down constrained problem
%   (\ref{eq:min_PeakSeg}).  Since Definition~\ref{def:U} contains
%   non-strict inequality constraints, the optimal solution may include
%   adjacent segments with equal mean values. In that case, the model is
%   not directly interpretable in terms of peaks and background, so we
%   discard the model. We expected the speed of the algorithm to be
%   consistent with the $O(n\log n)$ time complexity of other functional
%   pruning algorithms such as Segmentor.
% \item[MACS] is a heuristic algorithm with unknown time complexity from
%   the bioinformatics literature \citep{MACS}. We consider it as a
%   baseline, since it has been shown to achieve state-of-the-art peak
%   detection accuracy for sharp H3K4me3 histone mark data
%   \citep{HOCKING-PeakSeg}.
% \item[HMCanBroad] is a another heuristic algorithm with unknown time
%   complexity \citep{HMCan}. We consider it as a baseline, since it has
%   been shown to achieve state-of-the-art peak detection accuracy for
%   broad H3K36me3 histone mark data \citep{HOCKING-PeakSeg}.
% \end{description}

% We ran each algorithm on the McGill ChIP-seq benchmark data sets
% \citep{HOCKING2016-chipseq}. We begin by comparing the speed,
% feasibility, and optimality of the three optimization-based
% implementations (Segmentor, PeakSegDP, coseg).

\subsection{GPDPA has log-linear time complexity empirically}
\label{sec:results_time}

Overall there are 2752 labeled count data vectors $\mathbf y_m$ to segment,
varying in size from $n=87$ to $n=263169$ data. For each count data
vector $\mathbf y_m$, we ran each algorithm (CDPA, PDPA, GDPDA) with a
maximum of $K=19$ segments.
% , allowing at most 9 peaks (one for
% each even-numbered segment), which is more than enough in these
% relatively small data sets.
To analyze the empirical time complexity,
we recorded the number of intervals stored in the $C_{k,t}$ cost
functions (Section~\ref{sec:implementation}), as well as the computation
time in seconds.


% TODO: define I?
As in the PDPA, the time complexity of our proposed GPDPA is
$O(K n I)$, which depends on the number of intervals $I$ (candidate
changepoints) stored in the $C_{k,t}$ cost functions
\citep{pruned-dp-new}. We observed that the number of intervals stored
by the GPDPA increases as a sub-linear function of the number of data
points $n$ (left panel of Figure~\ref{fig:timings}). For the largest data
set ($n=263169$), the algorithm stored only mean=16 and maximum=43
intervals (mean and maximium computed over all cost functions
$C_{k,t}$ so is deterministic for a given data set). The most
intervals stored in any single $C_{k,t}$ function was 253 for one data set with $n=7776$. These results
suggest that our proposed GPDPA stores on average only $O(\log n)$
intervals (possible changepoints), as in the original PDPA. The
overall empirical time complexity is thus $O(K n \log n)$ for $K$
segments and $n$ data points.

We recorded the timings of each algorithm for computing models with up
to $K=19$ segments. Since $K$ is constant, the expected time
complexity was $O(n^2)$ for the CDPA and $O(n \log n)$ for the PDPA
and GPDPA. In agreement with these expectations, our proposed GPDPA
shows $O(n\log n)$ asymptotic timings similar to the PDPA (right panel of
Figure~\ref{fig:timings}). 
The right panel of
Figure~\ref{fig:timings} also shows that the $O(n^2)$ CDPA algorithm is slower than the other
two algorithms, especially for larger data sets. For the largest count
data vector ($n=263169$), the CDPA took over two hours, but the GPDPA
took only
% H3K36me3_TDH_immune        3 McGill0001  146.680 263169
% chr10:18761902-22380580
about two minutes. Our proposed GPDPA is nearly as fast as MACS
\citep{MACS}, a heuristic from the bioinformatics literature which
took about 1 minute to compute 10 peak models for this data set. 
%The MACS heuristic uses a Poisson significance test in a sliding window, sacrificing optimality for speed.

The total computation time to process all 2752 count data vectors was
156 hours for the CDPA, and only 6 hours for the GPDPA (26 times
faster). Overall, these results suggest that our proposed GPDPA enjoys
$O(n\log n)$ time complexity in ChIP-seq data, which makes it possible
to use for the very large data sets that are now common in the field of genomics.


\subsection{GPDPA is more accurate than baselines in terms of test AUC}
\label{sec:test-auc}

We wanted to compare the peak detection accuracy of our proposed
algorithm with others from the bioinformatics literature, which
typically report many false positive peaks using default parameter
settings. 
% Therefore, using the total number of incorrectly predicted
% labels as the evaluation metric would not show all relevant differences between methods (see
% Supplementary Figure 1). 
In a typical analysis, to control the false positive rate, the default
peak list is pruned by only considering the top $p$ peaks, according
to some likelihood or significance threshold. For example, the MACS
algorithm of \citet{MACS} uses a q-value threshold parameter, and the
HMCanBroad algorithm of \citet{HMCan} uses a finalThreshold parameter
(higher thresholds result in more false positives). For changepoint
models with a learned penalty function $f$
(Section~\ref{sec:supervised}), the threshold is a constant $\beta\in\RR$
which is added when selecting the number of segments
$\kappa_m(\exp(f(x_m)+\beta))$ (larger constants $\beta$ result in
larger penalties, fewer segments, and fewer false positives). 

To account for this pruning step in our evaluation, we used Receiver
Operating Characteristic (ROC) curve analysis. For each threshold
parameter, we computed the false positive rate and true positive rate
using the labels, which results in one point on the ROC curve. The
area under the curve (AUC) is computed by varying the threshold
parameter over its entire range (from a complete list of peaks with
many false and true positives, to a completely pruned/empty list of
peaks with FPR=TPR=0, see Supplementary Figure 3 for an illustration).
Because the largest peak list does not necessarily predict peaks in
all positive labels, we linearly extrapolate each ROC curve to
TPR=FPR=1 in order to compute AUC (see Supplementary Figure 5 for an
illustration of how the ROC/AUC is computed). To estimate the variance
of AUC on each data set, we use four-fold cross-validation. Each
labeled count data vector was randomly assigned a fold ID from 1 to 4
and then ROC curves and test AUC were computed for each fold ID.

% The total
% number of incorrect labels can be un-informative in data sets with
% unbalanced labels (unequal numbers of possible false positives and
% false negatives). Because the ChIP-seq data sets we examined are
% unbalanced (more possible false positives than false negatives), we
% observed similar accuracy for some algorithms in terms of total number
% of incorrect labels (see supplementary Figure~1). In order to see the
% differences between such algorithms, we decided to use ROC/AUC
% analysis for evaluation. This choice is also justified from an applied
% perspective, in which genomic data analysts frequently vary the
% significance threshold or penalty parameter in order to evaluate
% models with different numbers of peaks. We compute Receiver Operating
% Characteristic (ROC) curves by varying a significance/penalty
% parameter that controls the number of peaks detected. As in binary
% classification, Area Under the Curve (AUC) can be used to evaluate the
% overall accuracy of a particular model. For more details about how to
% compute the number of incorrect labels and AUC in this context, see
% \citep{HOCKING2016-chipseq}.


% \subsection{Other algorithms to compare against}
 
% Most existing algorithms can be used for accurate peak detection in
% either sharp H3K4me3 data, or broad H3K36me3 data, but not both. For
% example, the HMCanBroad algorithm of \citet{HMCan} was shown to yield
% accurate peak detection in broad H3K36me3 data, but not sharp H3K4me3
% data \citep{HOCKING2016-chipseq}. In contrast, \citet{HOCKING-PeakSeg}
% showed that a Constrained Dynamic Programming Algorithm (CDPA) for
% approximately computing the PeakSeg model achieves state-of-the-art
% peak detection accuracy in both sharp and broad data. However, the
% quadratic $O(Kn^2)$ time complexity of the CDPA makes it too slow to
% run on large ChIP-seq data sets.

% In this section, we show that our proposed GPDPA can be used to
% overcome this speed drawback, while maintaining state-of-the-art
% accuracy. To show the importance of enforcing the up-down constraint,
% we consider the unconstrained Pruned Dynamic Programming Algorithm
% (PDPA) of \citet{pruned-dp} as a baseline
% (Table~\ref{tab:contribution}). We also compare against two popular
% heuristics from the bioinformatics literature (MACS, \citet{MACS};
% HMCanBroad, \citet{HMCan}), in order to demonstrate that constrained 
% optimization algorithms such as the CDPA and GPDPA are more accurate.

%\subsection{Peak detection accuracy in ChIP-seq data}

% To compare the accuracy of the algorithms in the benchmark data sets,
% we computed false negative and false positive rates using labels
% that indicate presence or absence of peaks in specific samples and
% genomic regions \citep{HOCKING2016-chipseq}. Briefly, a false negative
% occurs when no peak is predicted in a region with a positive label,
% and a false positive occurs when a peak is predicted in a region with
% a negative label.  
% We performed 4-fold cross-validation to
% estimate the test error of each algorithm. For each of the 7 data
% sets, we randomly assigned labeled data to one of four folds. For each
% fold, we treat it as a test set, and train a model using all other
% folds.

\begin{figure*}[t!]
  \centering 
  %\includegraphics[width=\textwidth]{figure-test-error-mean}
  \includegraphics[width=\textwidth]{figure-all-cv}
  \vskip -0.5cm
  \caption{Four-fold cross-validation was used to estimate peak
    detection accuracy (black points show predicted
    AUC in each test fold). Each panel shows one of seven ChIP-seq data
    sets, labeled by pattern/experiment (Broad H3K36me3), labeler
    (AM), and cell types (immune).  It is clear that the proposed
    GPDPA is just as accurate as the previous state-of-the-art CDPA,
    and both are more accurate than the other baseline methods.
% Interactive version
%     available at
%     \url{http://bl.ocks.org/tdhock/raw/886575874144c3b172ce6b7d7d770b9f/}
  }
  \label{fig:test-auc}
\end{figure*}

% To demonstrate that changepoint detection algorithms are more accurate
% than typical heuristics, we also
% compared with the MACS and HMCanBroad methods \citep{MACS,
%   HMCan}. MACS is a popular heuristic for data with a sharp peak
% pattern such as H3K4me3, and \mbox{HMCanBroad} is a popular heuristic
% for data with a broad peak pattern such as H3K36me3. Although they are
% not designed for supervised learning, we trained them by performing
% grid search over a single significance threshold parameter that
% controls the number of peaks detected (qvalue for MACS and
% finalThreshold for HMCanBroad). We computed ROC/AUC by varying these
% parameters.
% Note that since these are not changepoint detection algorithms,
% there is no parameter for we did not use these algorithms in the
% speed comparison
% Without this training step, the unsupervised default parameters of
% these algorithms yield high false positive rates.


% p-values in the following paragraph computed in figure-all-cv.R
In each of the seven data sets in the histone benchmark,
%\citep{HOCKING2016-chipseq}, 
we performed four-fold cross-validation and computed test AUC (area
under the Receiver Operating Characteristic curve) to estimate the
accuracy of each algorithm. For the changepoint models, we learned
penalty functions using the labels in each train set
(Section~\ref{sec:supervised}). The previous algorithm with
state-of-the-art accuracy on this benchmark was the CDPA, which
enforces the up-down constraint on segment means. We expected our
proposed GPDPA to perform just as well, since it also enforces that
constraint. In agreement with our expectation, we observed that the
CDPA and GPDPA yield comparable test AUC in all seven data sets
(Figure~\ref{fig:test-auc}).
%               set.name    p.value      estimate      CDPA     GPDPA
% 1:  H3K36me3_AM_immune 0.34399895 -0.0002065765 0.9808486 0.9810551
% 2: H3K36me3_TDH_immune        NaN  0.0000000000 0.9999356 0.9999356
% 3:  H3K36me3_TDH_other 0.39100222  0.0032242063 0.9789807 0.9757564
% 4:  H3K4me3_PGP_immune 0.05558428  0.0144763916 0.8874555 0.8729791
% 5:  H3K4me3_TDH_immune 0.21427302  0.0006383032 0.9486926 0.9480543
% 6:   H3K4me3_TDH_other 0.25594687 -0.0016846727 0.9841230 0.9858077
% 7:   H3K4me3_XJ_immune 0.01999439 -0.0159414879 0.8966547 0.9125962
In five of the seven data sets,
there was no significant difference in test AUC ($\text{p-value}>0.2$ in
two-sided paired $t_3$-test). In one of the two other data sets
(H3K4me3 PGP immune), the GPDPA (mean AUC=0.873) was slightly less
accurate than the CDPA (mean AUC=0.887, p-value=0.056); in the other
data set (H3K4me3 XJ immune) the GPDPA (mean AUC=0.913) was significantly
more accurate than the CDPA (mean AUC=0.897, p-value=0.02). In contrast, the
unconstrained PDPA had significantly lower test AUC in all seven data sets
(p-value$<0.04$), because of lower true positive rates. These results
provide convincing evidence that the up-down constraint is necessary for
optimal peak detection accuracy.
%               set.name      p.value    estimate     GPDPA      PDPA
% 1:  H3K36me3_AM_immune 0.0033807744 -0.11032766 0.9810551 0.8707275
% 2: H3K36me3_TDH_immune 0.0110653684 -0.23217402 0.9999356 0.7677616
% 3:  H3K36me3_TDH_other 0.0668829019 -0.27605407 0.9757564 0.6997024
% 4:  H3K4me3_PGP_immune 0.0113958655 -0.16280619 0.8729791 0.7101729
% 5:  H3K4me3_TDH_immune 0.0001688006 -0.22460386 0.9480543 0.7234504
% 6:   H3K4me3_TDH_other 0.0076857759 -0.22943225 0.9858077 0.7563754
% 7:   H3K4me3_XJ_immune 0.0368826308 -0.09290677 0.9125962 0.8196894

Since the baseline HMCanBroad algorithm was designed for data with a
broad peak pattern, we expected it to perform well in the H3K36me3
data. In agreement with this expectation, HMCanBroad showed
state-of-the-art test AUC in two H3K36me3 data sets (broad peak
pattern), but was very inaccurate in four H3K4me3 data sets (sharp
peak pattern). We expected the baseline MACS algorithm to perform well
in the H3K4me3 data sets, since it was designed for data with a sharp
peak pattern. In contrast to this expectation, MACS had test AUC
values much lower than the optimal changepoint algorithms in all seven data
sets (Figure~\ref{fig:test-auc}). These results suggest that for
detecting peaks in ChIP-seq data, the optimal changepoint algorithms are more
accurate than the heuristics from the bioinformatics literature.

\subsection{Learned penalties have higher test AUC than oracle
  penalties}

In Section~\ref{sec:supervised} we proposed to select the number of
segments in changepoint models using two kinds of model complexity
functions $\mathcal C$. The oracle model complexity~(\ref{eq:oracle})
of \citet{cleynen2013segmentation} is a relatively complex expression
 motivated by statistical arguments; the linear model complexity
simply measures the number of segments. In this section we compare
these methods in terms of test AUC.

We consider learning a one-parameter penalty function consisting of a
constant penalty $\lambda$, given either the linear or oracle model
complexity function. We expected the oracle model complexity to result
in higher test AUC, because of its statistical motivation. The second
row of Supplementary Figure 4 plots the distribution of test AUC
values for one model complexity function versus the other. Contrary to
our expectation, for all three changepoint algorithms (CDPA, GPDPA,
PDPA), the linear and oracle penalties showed no significant
difference in test AUC (mean difference from 0.00004 to 0.0006,
$\text{p-value}>0.05$ in paired $t_{27}$-test). These data indicate
that, despite the statistical arguments that motivate the oracle model
complexity, it is not more accurate than the simple linear model
complexity for peak detection in real genomic data.

We also compare learning a penalty function with either one or
multiple parameters, given the linear model complexity function. We
expected higher test AUC for the penalty function with multiple
parameters. The first row of Supplementary Figure 4 plots the
distribution of test AUC values for one penalty function versus the
other. In agreement with our expectation, for all three changepoint
algorithms, the multi-parameter penalty function has a significantly
larger test AUC (mean difference from 0.003 to 0.005,
$\text{p-value}<0.07$). These data indicate that learning a
multi-parameter penalty function should be preferred for accurate peak
detection in genomic data.

\subsection{Supervised is more accurate than unsupervised model traning}
\label{sec:test-accuracy}
Unsupervised algorithms are common for peak detection in genomic data,
and our changepoint penalty learning method is to the best of our
knowledge the first supervised method for this problem. We therefore
wanted to demonstrate the superior accuracy of the supervised
approach. In this section, we compare supervised and unsupervised
algorithms in terms of percent correctly predicted labels in four-fold
cross-validation experiments on each of the seven data sets.
 
First, we compared supervised single-parameter learning (grid search
on a peak detection threshold) with unsupervised
learning (keeping that threshold at the suggested default value). For
unsupervised learning, default significance thresholds were used for
HMCanBroad (finalThreshold=10) and MACS (qvalue=0.05); elbow/hinge
heuristic for oracle penalty was used for PDPA/CDPA/GPDPA, as
implemented in Segmentor3IsBack R package
\citep{cleynen2013segmentation}. We expected that supervised learning
would result in more accurate peak predictions. In agreement with
these expectations, we observed that supervised learning had
significantly higher test accuracy than unsupervised learning for
almost every algorithm and data set (Supplementary Figure~5). The only
exception was in data set H3K36me3 TDH other, for which the
unsupervised GPDPA and CDPA were slightly more accurate (mean
difference of 6.9--8.2\% accuracy, not significant,
$\text{p-value}>0.3$ in paired $t_3$-test). This makes sense because
that data set has the fewest labels (200) to learn from, whereas the
other data sets had at least three times as many labels
(630--3834). Overall these data suggest that supervised learning
should be preferred for accurate peak detection, especially when there
are several hundred or more labels.
% > pval.vised[order(estimate, p.value)]
%                 algo.fac            set.name    estimate      p.value
%  1:      GPDPA(proposed)  H3K36me3_TDH_other -8.24404762 0.3001819117
%  2:  CDPA(previous best)  H3K36me3_TDH_other -6.90476190 0.4053890380
%  3:       MACS(baseline)  H3K4me3_PGP_immune -0.18936515 0.1876193578
%  4:       MACS(baseline)  H3K4me3_TDH_immune -0.18070685 0.6524463582
%  5: HMCanBroad(baseline)  H3K4me3_PGP_immune -0.03056261 0.9483889468
%  6:      GPDPA(proposed)  H3K4me3_TDH_immune  0.18909616 0.9105565797
%  7: HMCanBroad(baseline)  H3K4me3_TDH_immune  0.49049867 0.4853719594
%  8: HMCanBroad(baseline)   H3K4me3_XJ_immune  1.05251230 0.1304387805
%  9:      GPDPA(proposed)  H3K4me3_PGP_immune  1.05292332 0.6062642662
% 10:       MACS(baseline)   H3K4me3_XJ_immune  1.39147889 0.1754710720
% 11:  CDPA(previous best)  H3K4me3_TDH_immune  1.45740287 0.6129652579
% 12:       MACS(baseline)  H3K36me3_TDH_other  1.62202381 0.3445014627
% 13:      GPDPA(proposed)   H3K4me3_TDH_other  1.70579331 0.4432551334
% 14:  CDPA(previous best)   H3K4me3_TDH_other  2.31334667 0.4799962260
% 15:  CDPA(previous best)  H3K4me3_PGP_immune  2.56645725 0.2106380401
% 16:       MACS(baseline)  H3K36me3_AM_immune  2.63454943 0.0063024134
% 17: HMCanBroad(baseline)   H3K4me3_TDH_other  4.67030993 0.0391255673
% 18:       MACS(baseline)   H3K4me3_TDH_other  7.36696942 0.0123899067
% 19: HMCanBroad(baseline)  H3K36me3_AM_immune 10.31913336 0.0065854723
% 20:      GPDPA(proposed)   H3K4me3_XJ_immune 10.61857895 0.0304047826
% 21:  PDPA(unconstrained)  H3K4me3_PGP_immune 11.00403038 0.0312535074
% 22:      GPDPA(proposed)  H3K36me3_AM_immune 11.17811134 0.0006260584
% 23:       MACS(baseline) H3K36me3_TDH_immune 11.92640693 0.0030592324
% 24:  CDPA(previous best)  H3K36me3_AM_immune 11.94355564 0.0006525856
% 25:  PDPA(unconstrained)  H3K4me3_TDH_immune 13.76208091 0.0686503988
% 26:  CDPA(previous best)   H3K4me3_XJ_immune 15.08611759 0.0085225312
% 27: HMCanBroad(baseline)  H3K36me3_TDH_other 16.50297619 0.0455251964
% 28:  PDPA(unconstrained)   H3K4me3_TDH_other 17.18070094 0.0470722767
% 29:  CDPA(previous best) H3K36me3_TDH_immune 18.60853432 0.0428782343
% 30:      GPDPA(proposed) H3K36me3_TDH_immune 18.60853432 0.0428782343
% 31:  PDPA(unconstrained)  H3K36me3_AM_immune 18.89105862 0.0400622259
% 32:  PDPA(unconstrained)  H3K36me3_TDH_other 21.25000000 0.2237478578
% 33:  PDPA(unconstrained)   H3K4me3_XJ_immune 21.37378054 0.0112876939
% 34: HMCanBroad(baseline) H3K36me3_TDH_immune 23.78478664 0.0080498031
% 35:  PDPA(unconstrained) H3K36me3_TDH_immune 34.11564626 0.0030426713
%                 algo.fac            set.name    estimate      p.value
% > 

We also expected that learning multi-parameter penalty functions would
result in higher percent accuracy rates than single-parameter penalty
functions. In agreement with this expectation, we observed that
multiple parameters was at least as accurate as single parameters for
every data set and algorithm (Supplementary Figure~5). For example,
the GPDPA with multiple penalty parameters was significantly more
accurate on two data sets (mean difference of 1--3\% accuracy,
$\text{p-value}<0.05$ in paired $t_3$-test). Overall these data
suggest that the current state-of-the-art for peak detection in
labeled genomic data sets is achieved by the GPDPA with
multi-parameter supervised penalty learning.
% > pval.params[p.value>0.05]
%                algo.fac            set.name    estimate    p.value
%  1: PDPA(unconstrained)  H3K4me3_PGP_immune -3.84720383 0.07839404
%  2: CDPA(previous best)  H3K36me3_TDH_other -2.97619048 0.69442493
%  3:     GPDPA(proposed)  H3K4me3_PGP_immune -2.90087267 0.08488953
%  4: CDPA(previous best)   H3K4me3_XJ_immune -2.24078391 0.31281799
%  5:     GPDPA(proposed)  H3K36me3_TDH_other -2.08333333 0.80102936
%  6:     GPDPA(proposed)  H3K36me3_AM_immune -0.07837171 0.88889532
%  7:     GPDPA(proposed)   H3K4me3_XJ_immune -0.01208668 0.99391432
%  8: CDPA(previous best)  H3K36me3_AM_immune  0.03291194 0.95617200
%  9: PDPA(unconstrained) H3K36me3_TDH_immune  0.17006803 0.87288857
% 10: PDPA(unconstrained)   H3K4me3_XJ_immune  0.63357938 0.83302349
% 11: CDPA(previous best) H3K36me3_TDH_immune  1.36672851 0.23630707
% 12:     GPDPA(proposed) H3K36me3_TDH_immune  1.36672851 0.23630707
% 13: PDPA(unconstrained)  H3K36me3_AM_immune  3.92990464 0.20069319
% 14: PDPA(unconstrained)  H3K36me3_TDH_other 16.90476190 0.09957996
% > pval.params[p.value<0.05]
%               algo.fac           set.name   estimate     p.value
% 1: PDPA(unconstrained) H3K4me3_TDH_immune -7.5930692 0.022333755
% 2: PDPA(unconstrained)  H3K4me3_TDH_other -7.5023091 0.006671425
% 3: CDPA(previous best) H3K4me3_TDH_immune -3.2080761 0.004810735
% 4:     GPDPA(proposed) H3K4me3_TDH_immune -2.8750227 0.022657299
% 5: CDPA(previous best) H3K4me3_PGP_immune -2.7905288 0.036023329
% 6: CDPA(previous best)  H3K4me3_TDH_other -2.0295823 0.044339164
% 7:     GPDPA(proposed)  H3K4me3_TDH_other -0.9593083 0.045158010
% > 





% \begin{table}[b!]
%   \centering
%   \input{table-min-train-error}
%   \caption{Comparison of algorithms in the ChIP-seq data sets,
%     in terms of minimum train error and number of feasible models. 
%     For each of the 2752 separate segmentation problems, 
%     each algorithm was run with several parameter values (see text for details), 
%     and we selected the parameter with the minimum number of incorrect labels
%     (errors = fp + fn). 
%     The new algorithm implemented in the coseg R package 
%     commits fewer false positives than the slower PeakSegDP heuristic, 
%     and fewer errors than the other baseline methods.
%     The new algorithm computed models that are feasible for the PeakSeg up-down constraint
%     more frequently than the unconstrained Segmentor algo,
%     but less frequently than the PeakSegDP algo.}
%   \label{tab:min-train-error}
% \end{table}

\section{Discussion and conclusions}
\label{sec:discussion}

Algorithms for changepoint detection can be classified in terms of
time complexity, optimality, constraints, and pruning techniques
(Table~1). In this paper, we investigated generalizing the functional
pruning technique originally discovered by \citet{pruned-dp} and
\citet{phd-johnson}. Our main contribution was showing that the
functional pruning technique can be used to compute optimal
changepoints subject to constraints on the directions of changes
(Section~\ref{sec:algorithms}, Theorem~\ref{thm:gpdpa}), which results in
an efficient Generalized Pruned Dynamic Programming Algorithm (GPDPA).

We showed that the GPDPA enjoys the same log-linear $O(Kn\log n)$ time
complexity as the original unconstrained PDPA, when applied to peak
detection in ChIP-seq data sets (Section~\ref{sec:results_time},
Figure~\ref{fig:timings}). We also observed that the up-down
constrained GPDPA is much more accurate than the unconstrained PDPA,
in terms of minimum train error (Section~\ref{sec:min-train-error},
Figure~\ref{fig:PDPA-infeasible-error-compare}), test AUC
(Section~\ref{sec:test-auc}, Figure~\ref{fig:test-auc}), and test
accuracy (Section~\ref{sec:test-accuracy}, Supplementary
Figure~5). These results suggest that the up-down constraint is
necessary for computing a changepoint model with optimal peak
detection accuracy. Indeed, we observed that the GPDPA enjoys the same
state-of-the-art accuracy as the previous best, the relatively slow
quadratic $O(Kn^2)$ time CDPA.

We observed that the heuristic algorithms which are popular in the
bioinformatics literature (MACS, HMCanBroad) are much less accurate
than the proposed GPDPA, in terms of minimum train error, test AUC, and
test accuracy. In the past these sub-optimal heuristics have been
preferred because of their speed. For example, the CDPA took 2 hours
to compute 10 peak models in the largest data set in the ChIP-seq
benchmark, whereas the GPDPA took 2 minutes, and the MACS heuristic
took 1 minute. Using our proposed GPDPA, it is now possible to compute
highly accurate models in an amount of time that is comparable to
heuristic algorithms. Our proposed GPDPA can now be used as an optimal
alternative to heuristic algorithms, even for large data
sets. Additionally, for \emph{any} model with $P$ peaks, due to the optimality of the GPDPA, it can be used 
with $K=2P+1$ segments to compute a more likely (or
equally likely) set of peaks (in terms of the Poisson likelihood of
the piecewise constant model with a segment for each peak and
background region).

The framework we have introduced for estimating changepoints when
there are constraints on parameters of neighboring segments can be
applied in other fields than genomics. For example, ideas from an
early draft of this paper
\citep{Hocking-constrained-changepoint-detection} have already been
used to obtain an efficient and optimal algorithm for computing a model with non-decreasing change constraints in
neuro spike train data \citep{Jewell2018}. More generally, constrained
changepoint detection models will be interesting to explore in the
context of other data such as time series and statistical process
monitoring.
 
\section{Reproducible Research Statement}

The source code and data used to create this manuscript (including all
figures) is available at\\
\url{https://github.com/tdhock/PeakSegFPOP-paper}


\section{Acknowledgements}
  
Toby Dylan Hocking and Guillaume Bourque were supported by a Discovery
Frontiers project grant, ``The Cancer Genome Collaboratory,'' jointly
sponsored by the Natural Sciences and Engineering Research Council
(NSERC), Genome Canada (GC), the Canadian Institutes of Health
Research (CIHR) and the Canada Foundation for Innovation (CFI). Paul
Fearnhead acknowledges EPSRC grant EP/N031938/1 (StatScale).
Guillem Rigaill acknowledges an ATIGE  grant from G\'enopole.

% \begin{supplement}[id=suppA]
%   \sname{Supplement A}
%   \stitle{Title}
%   \slink[doi]{COMPLETED BY THE TYPESETTER}
%   \sdatatype{.pdf}
%   \sdescription{Some text}
% \end{supplement}

 
%\bibliographystyle{abbrvnat}
\bibliography{refs}
 


% AOS,AOAS: If there are supplements please fill:
%\begin{supplement}[id=suppA]
%  \sname{Supplement A}
%  \stitle{Title}
%  \slink[doi]{10.1214/00-AOASXXXXSUPP}
%  \sdatatype{.pdf}" 
%  \sdescription{Some text}
%\end{supplement}


\end{document}
