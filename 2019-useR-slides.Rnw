% -*- compile-command: "make 2019-useR-slides.pdf" -*-
\documentclass{beamer}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{fit,positioning}%for \node rectangle plate notation
\usepackage[all]{xy}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{algorithmic}
\usepackage{multirow}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\Lik}{Lik}
\DeclareMathOperator*{\PoissonLoss}{PoissonLoss}
\DeclareMathOperator*{\Peaks}{Peaks}
\DeclareMathOperator*{\Segments}{Segments}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\minimize}{minimize}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\RR}{\mathbb R}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\NN}{\mathbb N}
\newcommand{\z}{$z = 2, 4, 3, 5, 1$} 

\newcommand{\algo}[1]{\textcolor{#1}{#1}}
\definecolor{PDPA}{HTML}{66C2A5}
\definecolor{CDPA}{HTML}{FC8D62}
\definecolor{GPDPA}{HTML}{4D4D4D}

% Set transparency of non-highlighted sections in the table of
% contents slide.
% \setbeamertemplate{section in toc shaded}[default][100]
% \AtBeginSection[]
% {
%   \setbeamercolor{section in toc}{fg=red} 
%   \setbeamercolor{section in toc shaded}{fg=black} 
%   \begin{frame}
%     \tableofcontents[currentsection]
%   \end{frame}
% }

\begin{document}

\title{A Generalized Functional Pruning Optimal Partitioning (GFPOP)
  Algorithm for Peak Detection in Large Genomic Data}

\author{
PeakSegDisk R package / arXiv:1810.00117\\[0.5cm]
  Toby Dylan Hocking, toby.hocking@nau.edu, joint work with 
Guillem Rigaill, Guillaume Bourque, Paul Fearnhead
}

\date{10 July 2019}

\maketitle


\begin{frame}
  \frametitle{Problem: find peaks in each of several samples}
  \includegraphics[width=\textwidth]{screenshot-ucsc-edited}

  \begin{itemize}
  \item Grey profiles are noisy aligned read count signals -- \\peaks
    are genomic locations with protein binding sites.
  \item Black bars are peaks called by MACS2 (Zhang et al, 2008) -- many
    false positives! (black bars where there is only noise)
  \item From a machine learning perspective, this is binary
    classification (positive=peaks, negative=noise).
  \end{itemize}
\end{frame}

% \begin{frame}
%   \frametitle{Previous work in genomic peak detection}
%   \begin{itemize}
%   \item Model-based analysis of ChIP-Seq (MACS), Zhang et al, 2008.
%   \item SICER, Zang et al, 2009.
%   \item HOMER, Heinz et al, 2010.
%   \item CCAT, Xu et al, 2010.
%   \item RSEG, Song et al, 2011.
%   \item Triform, Kornacker et al, 2012.
%   \item Histone modifications in cancer (HMCan), Ashoor et al, 2013.
%   \item PeakSeg, Hocking, Rigaill, Bourque, ICML 2015.
%   %\item PeakSegJoint Hocking and Bourque, arXiv:1506.01286.
%   \item ... dozens of others.
%   \end{itemize}
%   Two big questions: how to choose the best...
%   \begin{itemize}
%   \item ...algorithm? (testing)
%   \item \alert<1>{...parameters? (training)}
%   \end{itemize}
% \end{frame}

% \begin{frame}[fragile]
%   \frametitle{How to choose parameters of unsupervised peak
%     detectors?}
% \scriptsize
% 19 parameters for Model-based analysis of ChIP-Seq (MACS), Zhang et al, 2008.
% \begin{verbatim}
%   [-g GSIZE]
%   [-s TSIZE] [--bw BW] [-m MFOLD MFOLD] [--fix-bimodal]
%   [--nomodel] [--extsize EXTSIZE | --shiftsize SHIFTSIZE]
%   [-q QVALUE | -p PVALUE | -F FOLDENRICHMENT] [--to-large]
%   [--down-sample] [--seed SEED] [--nolambda]
%   [--slocal SMALLLOCAL] [--llocal LARGELOCAL]
%   [--shift-control] [--half-ext] [--broad]
%   [--broad-cutoff BROADCUTOFF] [--call-summits]
% \end{verbatim}
% 10 parameters for Histone modifications in cancer (HMCan),
% Ashoor et al, 2013.
% \begin{verbatim}
% minLength 145
% medLength 150
% maxLength 155
% smallBinLength 50
% largeBinLength 100000
% pvalueThreshold 0.01
% mergeDistance 200
% iterationThreshold 5
% finalThreshold 0
% maxIter 20
% \end{verbatim}
% \end{frame}
 
% \begin{frame}
%   \frametitle{Which macs parameter yis best for these data?}
%   \includegraphics[width=1\textwidth]{figure-macs-problem.png}
% \end{frame}

% \begin{frame}
%   \frametitle{Compute likelihood/loss of piecewise constant model}
%   \includegraphics[width=1\textwidth]{figure-macs-problem-7-5.png}
%   % $\PoissonLoss(\mathbf z, \mathbf m) = \sum_{i=1}^n m_i - z_i \log(m_i)$
%   % for count data $\mathbf z\in\ZZ_+^n$ 
%   % and segment mean model $\mathbf m\in\RR^n$.
% \end{frame}

% \begin{frame}
%   \frametitle{Idea: choose the parameter with a lower loss}
%   \includegraphics[width=1\textwidth]{figure-macs-problem-15.png}
% \end{frame}

% \begin{frame}
%   \frametitle{PeakSeg: search for the peaks with lowest loss}
%   \includegraphics[width=1\textwidth]{figure-macs-problem-PeakSeg.png}

%   Simple model with only one parameter (number of peaks).

%   %Choose the number of peaks via standard penalties (AIC, BIC,
%   %  ...)\\or learned penalties based on visual labels (more on this later).
% \end{frame}

% \begin{frame}
%   \frametitle{Maximum likelihood Poisson segmentation models}
%   \includegraphics[width=1\textwidth]{figure-Segmentor-PeakSeg}

%   \begin{itemize}
%   \item Previous work: unconstrained maximum likelihood mean\\
%     for $s$ segments ($s-1$ changes), Cleynen et al 2014.
%   \item Hocking et al, ICML 2015: PeakSeg constraint enforces up, down, up,
%     down changes (and not up, up, down). 
%   \item Odd-numbered segments are background noise,\\
%     even-numbered segments are peaks.
%   \item Constrained Dynamic Programming Algorithm, $O(n^2)$ time for $n$ data points.
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{But quadratic time is not fast enough for genomic data!}
%   \includegraphics[width=\textwidth]{figure-PDPA-timings-dp}
%   \begin{itemize}
%   \item Genomic data is large, $n \geq 10^6$.
%   \item Split into subsets? What if we split a peak in half?
%   \item Need linear time algorithm for analyzing whole data set.
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Statistical model is a piecewise constant Poisson mean}
%   H {\it et al.}, {\it ICML} 2015. 

%   \input{figure-PeakSeg}
%   \vskip -0.8cm    
%   \begin{itemize}
%   \item We have $n$ count data $z_1, \dots, z_n\in\ZZ_+$.
%   \item Fix the number of segments $S\in\{1, 2, \dots, n\}$.
%   \item Optimization variables: $S-1$ changepoints
%     $t_1 < \cdots < t_{S-1}$ and $S$ segment means $u_1,\dots,u_S\in\RR_+$.
%   \item Let $0=t_0<t_1 < \cdots < t_{S-1}<t_S=n$ be the segment
%     limits.
%   \item Statistical model: for every segment $s\in\{1,\dots,S\}$,
%     $z_i \stackrel{\text{iid}}{\sim} \text{Poisson}(u_s)$ for every data
%     point $i\in(t_{s-1},t_s]$.
%   \item PeakSeg up-down constraint: $u_1\leq u_2 \geq u_3 \leq u_4 \geq \cdots$
%   \item Want to find means $u_s$ which maximize the Poisson likelihood:
%     $P(Z = z_i|u_s) = u_s^{z_i} e^{-u_s} / (z_i!)$.
%   \item Equivalent to finding means $u_s$ which minimize the Poisson
%     loss: $\ell(u_s, z_i) = u_s - z_i\log u_s$.
%   % \item Comparison to Hidden Markov Model:
%   %   \begin{description}
%   %   \item[Likelihood] Same emission terms, no transition terms.
%   %   \item[Constraint] Number of changes rather than values.
%   %   \end{description}
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{Maximum likelihood changepoint detection with up-down constraints on adjacent segment means}
    
\only<1>{\input{figure-PeakSeg}}      
\only<2>{\input{figure-PeakSeg-unconstrained}}
\only<3>{\input{figure-PeakSeg-constrained}}
\vskip -1.4cm
\begin{align*}
    \minimize_{\substack{
  \mathbf u\in\RR^{S}
\\
   0=t_0<t_1<\cdots<t_{S-1}<t_S=n
  }} &\ \ 
    \sum_{k=1}^S\  \sum_{i=t_{s-1}+1}^{t_s} \ell( u_k,  z_i) 
\\
      \text{subject to \hskip 0.75cm} &\ \ \alert<2-3>{u_{k-1} \leq u_k\ \forall k\in\{2,4,\dots\},}
  \nonumber\\
  &\ \ \alert<2-3>{u_{k-1} \geq u_k\ \forall k\in\{3,5,\dots\}.}
  \nonumber 
\end{align*}
\vskip -0.4cm
\begin{itemize}  
\item One tuning parameter = number of segments $S\in\{1,3,\dots\}$.
\item Hard optimization problem, naively $O(n^S)$ time.
\item \alert<2>{Previous unconstrained model: not always up-down changes.}
\item \alert<3>{Interpretable: $P=(S-1)/2$ peaks (segments 2, 4, ...).}
\item H {\it et al.}, {\it ICML} 2015: $O(Sn^2)$ time approximate
  algorithm. 
\item H {\it et al.}, arXiv 2017: $O(Sn\log n)$ time optimal algorithm.
\end{itemize}
\end{frame} 

% \begin{frame}
%   \frametitle{Labels used to determine optimal number of peaks}
%   \includegraphics[width=\textwidth]{jss-figure-label-error-data}
  
%   One ChIP-seq data set with $N=1,254,751$ (only 82,233 shown).
% \end{frame}

\begin{frame}
  \frametitle{Penalized changepoint problem with up-down constraints on adjacent segment means}
  
  H {\it et al.}, {\it arXiv} 2018. Generalized Functional Pruning
  Optimal Partitioning Algorithm (GFPOP) solves for one penalty
  $\lambda\in\RR_+$ in $O(n\log n)$ time.

\vskip -0.5cm

\begin{align*}
  \label{eq:penalized_peakseg}
  \minimize_{
    \substack{
    \mathbf m\in\RR^n,\ \mathbf s\in\{0, 1\}^n\\
\mathbf c\in\{-1, 0,1\}^{n-1}\\
}
    } &\ \ 
  \sum_{i=1}^n \ell(m_i, z_i) + \lambda \sum_{i=1}^{n-1} I(c_i \neq 0) \\
  \text{subject to\ \ } &\ \text{no change: }c_t = 0 \Rightarrow m_t = m_{t+1}\text{ and }s_t=s_{t+1}
  \nonumber\\
&\ \text{go up: }c_t = 1 \Rightarrow m_t \leq m_{t+1}\text{ and }(s_t,s_{t+1})=(0,1),
  \nonumber\\
&\ \text{go down: } c_t = -1 \Rightarrow m_t \geq m_{t+1}\text{ and }(s_t,s_{t+1})=(1,0).
\nonumber
\end{align*}
\begin{minipage}{0.5\linewidth}
    \begin{tikzpicture}[->,>=latex,shorten >=1pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw}]

  \node[main node] (1) {$s=1$};
  \node[main node] (2) [below of=1] {$s=0$};

  \path[every node/.style={font=\sffamily\small}]
    (2) edge [bend left] node {$c=1, \leq, \lambda$} (1)
    (1) edge [bend left] node {$c=-1, \geq, \lambda$} (2);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.45\linewidth}
  Nodes=states $s$,\\
  Edges=changes $c$ (constraint, penalty).
\end{minipage}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Proposed algorithm is fast, empirically $O(n \log n)$}

  \begin{minipage}{0.50\textwidth}
    $O(\log n)$ candidate changepoints.

    \includegraphics[width=\textwidth]{jss-figure-target-intervals-models}
  \end{minipage}
  \begin{minipage}{0.46\textwidth}
    Overall $O(n \log n)$ time/space.

    \includegraphics[width=\textwidth]{jss-figure-target-intervals-models-computation}
  \end{minipage}

  Example: $n=10^7$ data, 1000 peaks. Previous algo would require 150
  TB of storage space and 12 weeks of computation time! With the right
  penalty $\lambda$ the proposed algo takes 1 hour, 80 GB.
\end{frame}

%% \begin{frame}[fragile]
%%   \frametitle{Implementation challenges and solutions}
%%   Problem: Need $O(n\log n)$ storage, which in big data ($n=10^7$) is
%%   too large (80GB) for memory.
%%   Solution: 
%%   \begin{itemize}
%%   \item Write
%%   \item 
%%   \end{itemize}
%% \end{frame}

\begin{frame}[fragile]
  \frametitle{First save data as coverage.bedGraph file with $n$ lines, 
    so algorithm only needs $O(\log n)$ memory / $O(n\log n)$ disk}
  
<<options, echo=FALSE>>=

options(prompt="R> ", width=50)
library("PeakSegDisk")
data(Mono27ac, package="PeakSegDisk")
##Mono27ac$coverage
dir.create("Mono27ac/chr11-60000-580000", showWarnings=FALSE, recursive=TRUE)
write.table(Mono27ac$coverage, "Mono27ac/chr11-60000-580000/coverage.bedGraph",
  col.names=FALSE, row.names=FALSE, quote=FALSE, sep="\t")

@ 

<<computeFit>>=

write.table(Mono27ac$coverage, 
  "Mono27ac/chr11-60000-580000/coverage.bedGraph",
  col.names=FALSE, row.names=FALSE, quote=FALSE, 
  sep="\t")

fit <- PeakSegDisk::problem.PeakSegFPOP(
  "Mono27ac/chr11-60000-580000", "10000")

fit$loss

@ 


\end{frame}

\begin{frame}[fragile]
  \frametitle{Visualization of count data and segmentation/peaks}
  
<<plotModel, fig.height=2 >>=

library("ggplot2")
ggplot() + theme_bw() + 
  coord_cartesian(xlim = c(2e5, 3e5)) +
  geom_step(aes(
    chromStart, count), 
    color = "grey50", data = Mono27ac$coverage) +
  geom_segment(aes(
    chromStart, mean, xend = chromEnd, yend = mean),
    color = "green", size = 1, data = fit$segments)

@ 


\end{frame}


 
\begin{frame}
  \frametitle{Labels used to determine optimal number of peaks}
  \includegraphics[width=\textwidth]{jss-figure-label-error-data-labels}

  Visually labeled regions (H {\it et al.}, {\it Bioinformatics} 2017). 
\end{frame}

\begin{frame}
  \frametitle{Labels used to determine optimal number of peaks}
  \includegraphics[width=\textwidth]{jss-figure-label-error-too-few}

  Penalty too large, too few peaks, 2 false negative labels.
\end{frame}

\begin{frame}
  \frametitle{Labels used to determine optimal number of peaks}
  \includegraphics[width=\textwidth]{jss-figure-label-error-too-many}

  Penalty too small, too many peaks, 3 false positive labels.
\end{frame}

\begin{frame}
  \frametitle{Labels used to determine optimal number of peaks}
  \includegraphics[width=\textwidth]{jss-figure-label-error}
  
  Models with 34--236 peaks have no label errors (midpoint=135).
\end{frame}



\begin{frame}
  \frametitle{Supervised changepoint penalty learning is highly accurate for both broad and sharp data/pattern types}

  \begin{center}
\vskip -0.5cm
      \begin{tikzpicture}[->,>=latex,shorten >=1pt,auto,node distance=2.5cm, thick]
    \node (L) {Labels $\mathcal L$};
    \node (y) [below of=L, node distance=1cm] {Interval $y$};
    \node (z) [right of=L] {Coverage $z$};
    \node (x) [right of=y] {Features $x$};
    \node (f) [below of=x, node distance=1cm] {Function $f$};
    \node (l) [right of=x] {Penalty $\lambda$};
    \node (p) [right of=z] {Mean $m$};
    \path 
    (L) edge (y)
    (z) edge (y)
    (z) edge (x)
    (y) edge (f)
    (x) edge (f)
    (f) edge (l)
    (x) edge (l)
    (l) edge (p)
    (z) edge (p)
    ;
    \node[rectangle, inner sep=0mm, fit= (L) (l),label=below left:{H {\it et al.}, ICML 2013}, xshift=-10mm, yshift=-1mm] {};
    \node[rectangle, inner sep=0mm, fit= (L) (l),label=below right:$N$ labeled contigs/samples, xshift=5mm, yshift=-1mm] {};
    \node[rectangle, inner sep=2mm,draw=black!100, fit= (L) (l)] {};
  \end{tikzpicture}
  \end{center}

  \includegraphics[width=\textwidth]{figure-test-error-dots}
  \vskip -0.5cm
  H {\it et al.}, {\it arXiv} 2017. 
  \begin{itemize}
  \item 4-fold cross-validation: train on 3/4 of labels, test on 1/4.
  \item Proposed up-down constrained algorithms (CDPA, GPDPA) state-of-the-art.
  \end{itemize}
  \scriptsize
  %\url{http://bl.ocks.org/tdhock/raw/886575874144c3b172ce6b7d7d770b9f/} 
\end{frame} 

\begin{frame}[fragile]
  \frametitle{Conclusions / thanks!}
  
  \includegraphics[width=\textwidth]{jss-figure-label-error}

  \begin{itemize}
  \item Proposed GFPOP algorithm computes global minimum of
    constrained changepoint problem in $O(n\log n)$ time, $O(n\log n)$
    disk, $O(\log n)$ memory.
  \item Peak predictions are highly accurate in labeled genomic data
    with two patterns (H3K4me3 sharp, H3K36me3 broad).
  \item C++ code with R interface:
    \url{https://CRAN.R-project.org/package=PeakSegDisk}
  \item Contact me: toby.hocking@nau.edu
  \end{itemize}

  
\end{frame}



\end{document}
